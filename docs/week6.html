<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Remotely Sensing Cities and Environments: Learning Diary - 6&nbsp; Classification (i)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./week7.html" rel="next">
<link href="./week5.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week6.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Classification (i)</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Remotely Sensing Cities and Environments: Learning Diary</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Personal introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to remote sensing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Xaringan</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Corrections</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Policy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Google Earth Engine</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week6.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Classification (i)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Classification (ii)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">SAR</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary"><span class="header-section-number">6.1</span> Summary</a>
  <ul class="collapse">
  <li><a href="#what-does-classification-refer-to" id="toc-what-does-classification-refer-to" class="nav-link" data-scroll-target="#what-does-classification-refer-to"><span class="header-section-number">6.1.1</span> What does ‘classification’ refer to?</a></li>
  <li><a href="#what-are-the-different-approaches-to-classifying-surface-types" id="toc-what-are-the-different-approaches-to-classifying-surface-types" class="nav-link" data-scroll-target="#what-are-the-different-approaches-to-classifying-surface-types"><span class="header-section-number">6.1.2</span> What are the different approaches to classifying surface types?</a></li>
  <li><a href="#cart-classification-and-regression-trees" id="toc-cart-classification-and-regression-trees" class="nav-link" data-scroll-target="#cart-classification-and-regression-trees"><span class="header-section-number">6.1.3</span> CART: Classification and regression trees</a></li>
  <li><a href="#random-forest" id="toc-random-forest" class="nav-link" data-scroll-target="#random-forest"><span class="header-section-number">6.1.4</span> Random Forest</a></li>
  <li><a href="#image-classification" id="toc-image-classification" class="nav-link" data-scroll-target="#image-classification"><span class="header-section-number">6.1.5</span> Image classification</a></li>
  <li><a href="#maximum-likelihood" id="toc-maximum-likelihood" class="nav-link" data-scroll-target="#maximum-likelihood"><span class="header-section-number">6.1.6</span> Maximum likelihood</a></li>
  <li><a href="#support-vector-machine-svm" id="toc-support-vector-machine-svm" class="nav-link" data-scroll-target="#support-vector-machine-svm"><span class="header-section-number">6.1.7</span> Support Vector Machine (SVM)</a></li>
  <li><a href="#additional-important-considerations" id="toc-additional-important-considerations" class="nav-link" data-scroll-target="#additional-important-considerations"><span class="header-section-number">6.1.8</span> Additional important considerations</a></li>
  </ul></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications"><span class="header-section-number">6.2</span> Applications</a></li>
  <li><a href="#reflections" id="toc-reflections" class="nav-link" data-scroll-target="#reflections"><span class="header-section-number">6.3</span> Reflections</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">6.4</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Classification (i)</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="summary" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="summary"><span class="header-section-number">6.1</span> Summary</h2>
<p>This week we were introduced to the principles and methods of classification in the context of remote sensing, focusing specifically on the role of machine learning (hereafter ML). Several ML methods were outlined including classification and regression trees (CART), random forests, maximum likelihood and support vector machine (SVM), and we also discussed image classification approaches (supervised vs unsupervised learning). Below I shall summarise the lecture content and offer a brief description of each classification method covered. Since this is newer content to me than some of what was covered in previous weeks, this summary section will be longer and more in depth as I had to spend more time learning what each method was about!</p>
<section id="what-does-classification-refer-to" class="level3" data-number="6.1.1">
<h3 data-number="6.1.1" class="anchored" data-anchor-id="what-does-classification-refer-to"><span class="header-section-number">6.1.1</span> What does ‘classification’ refer to?</h3>
<p>In the context of remote sensing, classification is the process of categorising all pixels in an image into classes or themes based on their spectral signatures. Often, this is used to label different land cover types/change, described by <a href="https://www.mdpi.com/2072-4292/12/7/1135">Talukdar <em>et al.,</em></a>2020 as being an ‘increasingly essential aspect of activities and applications, such as in planning for land use or global warming mitigation’. <a href="https://ieeexplore.ieee.org/abstract/document/7182258?casa_token=gJZrdw6s9zEAAAAA:I3bhaLbOuD4zm-Ljw22Ex9jS8tgPcji188UW7pGsOhRi8MrkVMXpB283jypHaMnYsqvb2tE_">Gómez-Chova <em>et al.,</em></a>2015 consolidate this, arguing that ‘among all the products that can be obtained from the acquired images, classification maps are perhaps the most relevant ones’, as ‘land-cover and land-use maps are mandatory in multitemporal studies and constitute useful inputs to processes such as the modeling of climate change, the study of oceanic currents, arctic studies, or postcatastrophe deployments.’</p>
</section>
<section id="what-are-the-different-approaches-to-classifying-surface-types" class="level3" data-number="6.1.2">
<h3 data-number="6.1.2" class="anchored" data-anchor-id="what-are-the-different-approaches-to-classifying-surface-types"><span class="header-section-number">6.1.2</span> What are the different approaches to classifying surface types?</h3>
<ol type="1">
<li>Expert systems</li>
</ol>
<ul>
<li><p>Designed to mirror human expertise/decision making in classification of EO data</p></li>
<li><p>Takes in human knowledge to emulate problem solving that usually requires human intelligence</p></li>
</ul>
<ol start="2" type="1">
<li>Machine learning (ML)</li>
</ol>
<ul>
<li><p>By contrast, ML is a set of techniques that allow computers to classify images without explicit programming</p></li>
<li><p>It uses algorithms that learn from data and improves over time (becomes more accurate) as it is exposed to more examples</p></li>
<li><p>It can then be used on new input data</p></li>
</ul>
</section>
<section id="cart-classification-and-regression-trees" class="level3" data-number="6.1.3">
<h3 data-number="6.1.3" class="anchored" data-anchor-id="cart-classification-and-regression-trees"><span class="header-section-number">6.1.3</span> CART: Classification and regression trees</h3>
<p>CART is a generic term for two types of decision trees; classification and regression trees. In short however, these both represent versatile supervised ML methods.</p>
<ul>
<li><p>Classification trees</p>
<ul>
<li>Used to classify data into discrete categories (ie. whether a day is cloudy or not)</li>
</ul></li>
<li><p>Regression trees</p>
<ul>
<li>Used to predict a continuous dependent variable (ie. house prices)</li>
</ul></li>
</ul>
<p>They are decision trees where each fork is split into a predictor variable and each node has a prediction for the target variable at the end. Nodes are split into sub-nodes based on a threshold value of an attribute. The root node is taken as the training set and is split into two by considering the best attribute and threshold value. Further, the subsets are also split using the same logic. This continues till the last pure sub-set is found in the tree or the maximum number of leaves possible in that growing tree.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="CART.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">CART diagram. Source: <a href="https://www.geo.fu-berlin.de/en/v/geo-it/gee/3-classification/3-1-methodical-background/3-1-1-cart/index.html">Freie Universität Berlin</a>, 2019</figcaption>
</figure>
</div>
<p>CART algorithms use Gini impurity to decide where to split the data. The algorithm iteratively divides the dataset into smaller subsets, choosing splits that decrease Gini impurity, aiming for homogenous nodes. This process continues until a stopping criterion is met, creating a tree where each leaf represents a predicted class or value, effectively using Gini impurity as a guide to build a model that can classify new instances. Unlike linear regression, where you seek a single coefficient used to estimate the slope of a relationship, CART provides a series of mean values for subsets of the dataset, making it suitable when dealing with non-linear datasets.</p>
<p>Overfitting is a potential problem in the use of CART, which occurs when the tree model becomes too complex - meaning it closely mirrors the training data, including its noise and outliers. The effect of this is a poor generalisation on unseen data, with the model instead capturing noise rather than the underlying pattern. To mitigate against this, techniques like pruning (reducing the size of the tree by removing sections that provide little power to classify instances), setting a maximum depth for the tree, or requiring a minimum number of samples per leaf are used.</p>
</section>
<section id="random-forest" class="level3" data-number="6.1.4">
<h3 data-number="6.1.4" class="anchored" data-anchor-id="random-forest"><span class="header-section-number">6.1.4</span> Random Forest</h3>
<p>Random Forest builds upon the decision trees described above - it’s an ensemble learning method that builds multiple decision trees during training and aggregates their predictions for more accurate and stable results. It randomly selects subsets of the training data and features to construct each tree, reducing the risk of overfitting. The final prediction is made by majority vote for classification tasks or averaging for regression, enhancing the predictive accuracy and robustness over single decision trees.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="randomforest.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Random Forest diagram. Source: <a href="https://medium.com/@roiyeho/random-forests-98892261dc49">Yehoshua</a> (2023)</figcaption>
</figure>
</div>
<p>Bootstrapping and out-of-bag (OOB) error are two additional features of Random Forest algorithms that need explaining. Bootstrapping is a technique where multiple datasets are created from the original by randomly sampling with replacement, used to train individual trees. Out-of-bag (OOB) error is an accuracy estimate calculated from predictions on the training instances not included in the bootstrap sample for a tree. It serves as an internal validation method, offering insights into the model’s performance without needing a separate test set.</p>
<p>Whilst Random Forest handles overfitting better than singular decision trees and improves its accuracy through ensemble learning, it is more complex - a problem which can lead to slower model training and prediction times and pose challenges in interpreting the model compared to a single decision tree. However, decision trees may struggle to achieve the level of accuracy as random forests on complex datasets.</p>
</section>
<section id="image-classification" class="level3" data-number="6.1.5">
<h3 data-number="6.1.5" class="anchored" data-anchor-id="image-classification"><span class="header-section-number">6.1.5</span> Image classification</h3>
<p>We also discussed image classification; the process whereby images are categorised into one or more classes based on their content. There are two method types for this, supervised and unsupervised.</p>
<ol type="1">
<li>Supervised</li>
</ol>
<ul>
<li><p>Uses labelled training data to classify pixels into categories</p></li>
<li><p>Algorithm learns from training data, where examples are labelled correctly</p></li>
<li><p>This is used to recognise patterns/features corresponding to each category</p></li>
<li><p>Overall process: selecting training samples -&gt; training the classifier -&gt; applying it to classify whole dataset</p></li>
<li><p>Parametric</p></li>
<li><p>EG. Maximum likelihood, Support Vector Machine (SVM)</p></li>
</ul>
<ol start="2" type="1">
<li>Unsupervised</li>
</ol>
<ul>
<li><p>Doesn’t require labelled training data</p></li>
<li><p>Algorithms automatically segment input data into clusters based on inherent patterns/data similarities</p></li>
<li><p>No a priori knowledge needed</p></li>
<li><p>Useful for when there are unknown data patterns or when specific class labels aren’t provided/available</p></li>
<li><p>Non-parametric</p></li>
<li><p>EG. Clustering (K-means), ISODATA</p></li>
</ul>
</section>
<section id="maximum-likelihood" class="level3" data-number="6.1.6">
<h3 data-number="6.1.6" class="anchored" data-anchor-id="maximum-likelihood"><span class="header-section-number">6.1.6</span> Maximum likelihood</h3>
<p>This is a decision rule classifier that assigns pixels/groups of pixels to the class with the highest probability of being correct based on a pixel’s spectral signature. To work it uses the mean and covariance of the classes in a multidimensional feature space to estimate probabilities.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="maximumlikelihood.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Maximum likelihood diagram. Source: <a href="https://blogs.sas.com/content/iml/2011/10/12/maximum-likelihood-estimation-in-sasiml.html">Wicklin,</a> 2011</figcaption>
</figure>
</div>
<p>This makes it a highly effective approach when distinguishing between classes with different statistical characteristics. It can also use a threshold for hyperparameter tuning through the input of a priori knowledge, however it must be noted that this isn’t always available.</p>
</section>
<section id="support-vector-machine-svm" class="level3" data-number="6.1.7">
<h3 data-number="6.1.7" class="anchored" data-anchor-id="support-vector-machine-svm"><span class="header-section-number">6.1.7</span> Support Vector Machine (SVM)</h3>
<p>Whilst similarly being a data classifying algorithm, SVMs work by finding the optimal hyperplane that separates different class labels in a high-dimensional space. Ultimately, it is a linear binary classifier (like logistic regression), but is effective on both linear and non-linear data, working by using kernel functions to transform nonlinear input space into a higher-dimensional space where it becomes easier to classify the data. It focuses on maximizing the margin between different classes, which enhances the model’s accuracy and robustness in classification tasks. To understand this method I found this video extremely helpful: https://www.youtube.com/watch?v=_YPScrckx28 but ultimately, it clearly explains how the algorithm seeks to find a singular hyperplane that best separates the data into categories.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="SVM.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Hyperplane separating the dataset into categories. Source: <a href="https://www.youtube.com/watch?v=_YPScrckx28">Visually Explained</a> (YouTube), 2022</figcaption>
</figure>
</div>
<p>Therefore, whilst SVMs and maximum likelihood are both approaches to classify data, they differ in some key ways. Whilst SVM is more robust and better suited for handling complex, non-linear data, maximum likelihood is preferential at times on the basis of its probabilistic foundation which makes it effective in remote sensing application.</p>
</section>
<section id="additional-important-considerations" class="level3" data-number="6.1.8">
<h3 data-number="6.1.8" class="anchored" data-anchor-id="additional-important-considerations"><span class="header-section-number">6.1.8</span> Additional important considerations</h3>
<p>Finally, we were reminded (much like in week 1) that no single algorithm was better than another. Instead, there are key considerations which must be taken when thinking about which approach to use, including:</p>
<ul>
<li><p>Whether you want to classify pixels or objects</p></li>
<li><p>Whether you want to run a hard or soft classification</p></li>
<li><p>Whether classifiers are even needed (is there a clear divide between bands? Can data just be thresholded?)</p></li>
<li><p>Which hyperparameters do we want to use to control the classifier?</p></li>
<li><p>Are you more worried about accuracy or interpretability?</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="tradeoffs.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">The trade off between achieveable accuracy and interpretability of ML algorithms. Source: <a href="https://www.researchgate.net/publication/359890656_Machine_Learning_and_Deep_Learning_--_A_review_for_Ecologists">Pichler et al.</a> 2022</figcaption>
</figure>
</div>
<p>At the end of the day, <strong>classification methods are different ways of slicing data</strong> <strong>- they can be made to seem more complicated than they really are!!</strong></p>
</section>
</section>
<section id="applications" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="applications"><span class="header-section-number">6.2</span> Applications</h2>
<p>What stood out to me from this week’s lecture content was the fact that there are so many considerations that go into picking a classifier. In particular, I really liked the diagram (above) that graphically presented the trade off between accuracy and interpretability of different algorithms as it really demonstrated how high accuracy didn’t necessarily represent the best choice, despite what I assumed going into this week. As a result, when I was doing reading for this week I found myself drawn to papers which reviewed and compared classifiers against one another - I shall outline some of my findings in this section.</p>
<p>The first that piqued my interest was that by <a href="https://www.mdpi.com/2072-4292/14/12/2758">Yao et al.,</a> 2022, who compared classifiers mentioned in the lecture content (random forest) against additional classifiers not discussed (object-oriented and deep neural networks) to see which were most accurate when classifying crops in Qinghai Province, China. They found that using a combination of random forest and deep neural networks, the method returned a model accuracy, training and predict time spent were better than that of using either classifier alone. I found it really interesting the way that they not only used GEE, but also Google Colab in their methodology, presented in this diagram below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="flowchart.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Random forest + deep neural network classification method flowchart. Source: <a href="https://www.mdpi.com/2072-4292/14/12/2758">Yao et al.</a> 2022</figcaption>
</figure>
</div>
<p>They actually note the strength of these platforms in the paper, describing how the ‘scalable and simple classification method proposed in this paper gives full play to the advantages of cloud platform in data and operation, and the traditional machine learning combined with deep learning can effectively improve the classification accuracy’. This line stood out to me as it really built upon the conclusions I drew from last week’s content about cloud computing representing an enormous development in the world of remote sensing research.</p>
<p>By contrast to the findings of <a href="https://www.mdpi.com/2072-4292/14/12/2758">Yao et al.,</a> 2022, <a href="https://www.researchgate.net/profile/Ilham-Jamaluddin/publication/357620992_Comparison_of_Google_Earth_Engine_GEE-based_Machine_Learning_Classifiers_for_Mangrove_Mapping/links/61d6a6f9b6b5667157cd10c3/Comparison-of-Google-Earth-Engine-GEE-based-Machine-Learning-Classifiers-for-Mangrove-Mapping.pdf">Kamal <em>et al.,</em></a>’s 2019 research found SVM to be the most suitable classifier out of random forest and CART approaches tested on efforts to map mangrove extents in Indonesia using GEE.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mangroveclassification.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Classifier accuracy assessment results. Source: <a href="https://www.researchgate.net/profile/Ilham-Jamaluddin/publication/357620992_Comparison_of_Google_Earth_Engine_GEE-based_Machine_Learning_Classifiers_for_Mangrove_Mapping/links/61d6a6f9b6b5667157cd10c3/Comparison-of-Google-Earth-Engine-GEE-based-Machine-Learning-Classifiers-for-Mangrove-Mapping.pdf">Kamal <em>et al.,</em></a> 2019</figcaption>
</figure>
</div>
<p>Whilst they noted the ability of all classifiers to detect mangrove objects (a key finding given the relevance + importance of mangrove monitoring for ecosystem stabilisation), SVM’s classification results were described as being <em>significantly</em> better than the other classification methods and the method showed the least amount of miss-classified pixels. This demonstrates exactly the point made during the lecture; there is no one-classifier-fits-all! Also consolidating the practical content was <a href="https://www.researchgate.net/profile/Ilham-Jamaluddin/publication/357620992_Comparison_of_Google_Earth_Engine_GEE-based_Machine_Learning_Classifiers_for_Mangrove_Mapping/links/61d6a6f9b6b5667157cd10c3/Comparison-of-Google-Earth-Engine-GEE-based-Machine-Learning-Classifiers-for-Mangrove-Mapping.pdf">Kamal <em>et al.,</em></a>‘s heralding of GEE, describing how it provides ’a set of the state-of-the-art classifiers for pixel-based classification’.</p>
<p>Other papers that I read but shan’t describe here include <a href="https://www.mdpi.com/2072-4292/9/12/1315">Hird <em>et al.</em>’s</a> 2017 use of classifiers in GEE to support wetland mapping in Canada, <a href="https://www.mdpi.com/2072-4292/13/4/586">Praticò <em>et al.</em>’s</a> (2021) classification application for forest habitat monitoring in Italy and <a href="https://www.mdpi.com/2072-4292/12/7/1220">Sarzynski <em>et al.</em>’s</a> 2020 mapping of oil palm plantations in Indonesia which used GEE’s quality classifiers. These papers all demonstrate the varied contexts in which classification methods have been used in robust GEE-based research to monitor landscape type/use/change!</p>
</section>
<section id="reflections" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="reflections"><span class="header-section-number">6.3</span> Reflections</h2>
<p>Going into this week, I really didn’t know very much about the different classification approaches available so had to spend quite a long time familiarising myself with them. I found watching YouTube explanations to be my best friend for the job and this meant that the summary section of this week’s blog post is longer than any of my previous ones - apologies for this!</p>
<p>I really enjoyed reading about the enormous variety of applications for each classifier and although I only mentioned environmentally-focused research papers, I also found a breadth of urban-based papers that had similarly trialed several classifiers and assessed their accuracy before proceeding with further analysis. I’m glad I did that literature review as it really consolidated the point made during the lecture about the range of applications for classifiers in remote sensing contexts. I avoided clicking on non EO-data related papers but did scroll past several that were medically related (notably, I saw lots of tumour research come up), which is always something I find interesting and reminds me that so many of the principles we learn about are transferable to entirely different industries/research topics.</p>
</section>
<section id="references" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="references"><span class="header-section-number">6.4</span> References</h2>
<ol type="1">
<li>Freie Universität Berlin (2019) ‘Classification and Regression Trees (CART) - Classifier’. Web page, available at: https://www.geo.fu-berlin.de/en/v/geo-it/gee/3-classification/3-1-methodical-background/3-1-1-cart/index.html</li>
<li>Gómez-Chova, L., Tuia, D., Moser, G., Camps-Valls, G. (2015) ‘Multimodal Classification of Remote Sensing Images: A Review and Future Directions’. <em>Proceedings of the IEEE,</em> vol.&nbsp;103, is. 9.</li>
<li>Hird, J.N., DeLancey, E.R., McDermid, G.J., Kariyeva, J. (2017) ‘Google Earth Engine, Open-Access Satellite Data, and Machine Learning in Support of Large-Area Probabilistic Wetland Mapping’. <em>Remote Sensing,</em> vol.&nbsp;9, is. 12.</li>
<li>Kamal, M., Jamaluddin, I., Parela, A., Farda, N.M. (2019) ‘Comparison of Google Earth Engine (GEE)-based machine learning classifiers for mangrove mapping’. <em>40th Asian Conference on Remote Sensing, ACRS.</em></li>
<li>Pichler, M., Hartig, F. (2022) ‘Machine Learning and Deep Learning -- A review for Ecologists’. <em>Biomedical Signal Processing,</em> vol.&nbsp;1.</li>
<li>Praticò, S., Solano, F., Di Fazio, S., Modica, G. (2021) ‘Machine Learning Classification of Mediterranean Forest Habitats in Google Earth Engine Based on Seasonal Sentinel-2 Time-Series and Input Image Composition Optimisation’. <em>Remote Sensing,</em> vol.&nbsp;13, is. 4.</li>
<li>Sarzynski, T., Giam, X., Carrasco, L., Lee, J.S.H. (2020) ‘Combining Radar and Optical Imagery to Map Oil Palm Plantations in Sumatra, Indonesia, Using the Google Earth Engine’. <em>Remote Sensing,</em> vol.&nbsp;12, is. 7.</li>
<li>Talukdar, S., Singha, P., Mahato, S., Pal, S., Liou, Y-A., Rahman, A. (2020) ‘Land-Use Land-Cover Classification by Machine Learning Classifiers for Satellite Observations—A Review’. <em>Remote Sensing,</em> vol.&nbsp;12, is. 7.</li>
<li>Visually Explained (2022) ‘Support Vector Machine (SVM) in 2 minutes’. YouTube video, available at: https://www.youtube.com/watch?v=_YPScrckx28</li>
<li>Wilkin, R. (2011) ‘Maximum likelihood estimation in SAS/IML’. Web page, available at: https://blogs.sas.com/content/iml/2011/10/12/maximum-likelihood-estimation-in-sasiml.html</li>
<li>Yao, J., Wu, J., Xiao, C., Zhang, Z., Li, J. (2022) ‘The Classification Method Study of Crops Remote Sensing with Deep Learning, Machine Learning, and Google Earth Engine’. <em>Remote Sensing,</em> vol.&nbsp;14, is. 12.</li>
<li>Yehoshua, R. (2023) ‘Random Forests’. Web page, available at: https://medium.com/@roiyeho/random-forests-98892261dc49</li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./week5.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Google Earth Engine</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./week7.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Classification (ii)</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>