[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Remotely Sensing Cities and Environments: Learning Diary",
    "section": "",
    "text": "Personal introduction\nHello! My name’s Hannah and this is my Quarto learning diary for CASA0023.\nFor a bit of background on me; I’m currently enrolled on the Social and Geographic Data Science MSc programme at UCL, but come from a background in physical geography after graduating from the University of Edinburgh in 2023. I was first introduced to remote sensing during my undergrad which saw many projects focus on remotely sensing forests and green spaces across Scotland. After a gentle introduction to different sensors, programs and earth-focused applications in first/second year, I sought more opportunities to combine my primary research interest, the cryosphere, with remote sensing. Fortunately for me the two go hand-in-hand and as a result, my final two years in Edinburgh were focused almost entirely on remote sensing of cold places. My dissertation saw me map ice algal blooms across the Greenland Ice Sheet using Sentinel-3 imagery on ENVI/SNAP/ArcGIS and this remains my magnum opus (I joke - the maps I made were extremely basic and honestly quite ugly).\nI’ve also worked for two companies as a remote sensing intern/geospatial analyst which taught me a great deal; the first was Space Intelligence in Edinburgh and the other was CF Partners in London. At Space Intelligence I worked on a land cover classification project the company had been awarded by the Tanzanian government looking to monitor deforestation, whilst at CF I was thrown in the deep end with SAR interferometry and Google Earth Engine to produce a forestry-related machine learning model. Before this point, almost all of my interactions with remotely sensed data had been during solo projects for uni, so it was cool to see what working in a team was like during these professional experiences.\nThis jumble of academic and professional experiences has exposed me to quite a range of data products (Sentinel-1,2,3, Landsat, WorldView, MODIS etc.) and applications (ENVI, GEE, Arc+QGIS, SNAP etc.), not to mention the associated headaches and frustrations that come with working in the field. These headaches haven’t put me off yet though as I selected this course keen to learn more about urban-focused EO data applications. My undergrad was very quantitative and environmentally-focused which left me often disregarding anything even vaguely ‘human’ or development-based. By the end of this course I hope to challenge that past opinion of mine and learn more about how the techniques I’m already familiar with can be used to support cities and the people who live in them.\nI hope you enjoy reading my learning diary!"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  Introduction to remote sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nThis lecture felt like it very much served as a ‘Remote sensing 101’; we looked at what remote sensing actually is, the two different kinds of sensors (passive versus active), the ways in which data collected by sensors interact with both the earth and the atmosphere and finally the 4 resolutions of remotely sensed data. All of this was used to demonstrate that there is no one sensor for all applications - the kind of research you’re undertaking will dictate which sensor and what kind of data is appropriate. To consolidate what we learnt in class, I produced a summary sheet of the taught content, displayed below.\n\n\n\nWeek 1 summary sheet. Image available on GitHub here."
  },
  {
    "objectID": "week1.html#applications",
    "href": "week1.html#applications",
    "title": "1  Introduction to remote sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nComing from a background in remote sensing for environmental monitoring that has seen me use SNAP & R quite extensively, I decided it best to dedicate my study time in week 1 to consider applications of remote sensing data that I was unfamiliar with. Quite often during my undergraduate degree I found myself falling into a trap of believing that anything that lay beyond the confines of strictly quantitative and highly scientific research was a waste of time and not worth paying attention to. Only now that I’ve graduated am I realising how narrow-minded and naive this perspective is; it really came to mind when during the lecture we were reminded that given the plethora of potential applications of remotely sensed data, there is no singular best sensor or optimum spatial/spectral/temporal resolution. \nSo, in an attempt to fix my old way of thinking, I am starting off CASA0023 and this learning diary by researching applications of remote sensing that sit beyond the confines of physical geography. To have some fun with it, I decided to try and find an example of a time remotely sensed data was used to address an unusual topic for every letter of the alphabet. I used a random word generator (https://randomwordgenerator.com/) to offer me a word which served as the starting point of my research. Below I have provided a brief description of articles that I came across during my research, many of which prompted me to fall down a rabbit hole of literature that I’d never come across before.\n\nABCDEFGHIJKLMNOPQRSTUvWXYZ\n\n\nAdolescent vulnerability in Indonesia: Toharudin et al., 2024\nToharudin et al., 2024 examined mental health issues in adolescents in Indonesia by combining a variety of variables including mobile phone usage, emotional disorder classifications, travel experiences as well as night light remote sensing data to see how behavioural disorders varied between young people in urban versus rural areas.\n\n\nClassifying punches in Olympic boxing using static RGB cameras: Stefański et al., 2023\nStefański et al., 2023 sought to propose a solution to address current issues regarding the classification of punches in Olympic boxing by using static RGB cameras opposite the ring to track and then classify athlete moves. This challenged conventional approaches to track athletes in combat sports that see athletes require wearable sensors.\n\n\nOn-site cocaine detection with an integrated near-infrared spectral sensor: Kranenburg et al., 2022\nIn response to the all-time high of illegal drug production/trafficking/seizures/usage, Kranenburg et al., 2022 explore the concept of an on-site drug detection device that uses a NIR spectral sensor that can be integrated into a smart phone. Their testing found the sensor to successfully exploit an array of resonant-cavity enhanced photodetectors to correctly classify 11 common illicit drugs 100% of the time. This is achieved by chemometric modelling of the response of 15 wavelength-specific pixels (chemometric is just a fancy word for mathematical methods that analyse chemical data).\n\n\nDinosaur fossils discovered using remotely piloted aircraft systems: Herridge-Berry et al., 2021\nDigging for dinosaur remains is limited by the typically inaccessible terrain surrounding potential archeological sites. Herridge-Berry et al., 2021 however offer a proof-of-concept test for the remote sensing of fossils (specifically ‘vertebrate boneheads’) in Dinosaur Provincial Park, Alberta as the case study. Due to the small size of most fossils, they suggest using Spectral Mixture Analysis after collecting data obtained by deploying a RGB camera onto a plane flying over a study site.\n\n\nAdvancing the egg industry using non-destructive optical sensing technologies: Ahmed et al. 2023\nIn acknowledgement of eggs being one of the best sources of protein and one of the most popular foods worldwide, Ahmed et al. 2023 wrote a review of ways in which technologies including satellites in space and remote sensors are currently used (and can in future be used) to turn the current egg industry into ‘Industry 4.0’.\n\n\nPredicting the distribution potential of an invasive frog in Hawaii using remotely sensed data: Bisrat et al., 2011\nBisrat et al., 2011 used 5 biophysical variables derived from MODIS as predictors for the potential distribution of Eleutherodactylus coqui (commonly known as the coqui frog), a species native to Puerto Rico but non-native and dangerous to ecological systems in Hawaii.\n\n\nIntegrating remote sensing for mapping garbage dump areas in Bahrain: Al-Joburi, 2017\nGarbage dumping is a prevalent issue in Bahrain, associated with worrying economic and environmental consequences. In response to this issue, Al-Joburi, 2017 was able to identify, locate and map possible garbage dump sites using Landsat imagery spanning 1972 to the present day.\n\n\nRemote sensing via hot air balloon across Yellowstone National Park: Planer-Friedrich et al. 2006\nTwo rapidly changing hydrothermal areas in Yellowstone National Park required mapping and monitoring, however limited budgets, a lack of personnel trained in remote sensing and strict unmanned UAV rules in USA were holding back observation efforts and management strategy implementation. Planer-Friedrich et al. 2006 responded to this by using a hot air balloon to take photos from above the areas.\n\n\nEstimating the population size of endangered iguanas in the Galápagos using drones: Varela-Jaramillo et al., 2023\nVarela-Jaramillo et al., 2023 outline the development of a drone-based method for the estimation of population size in Galápagos marine iguanas, Amblyrhynchus cristatus, finding drone-based surveys to outperform ground-based counts in all tests.\n\n\nMicrowave remote sensing of Jupiter’s atmosphere from an orbiting spacecraft: Janssen et al., 2005\nJanssen et al., 2005 demonstrate the promise of passive microwave sounding via an orbiting spacecraft to determine deep water stores in Jupiter to an accuracy that enables the discrimination of models for Jupiter’s origin.\n\n\nEstimating the Leaf Area Index (LAI) for ketchup farms using remote sensing images: Dorneles et al., 2023\nLAI is one of the main physiological parameters of the plant related to transpiration, productivity and rainfall interception. Dorneles et al., 2023 sought to measure LAI of an industrial tomato field used in ketchup production in Brazil using Sentinel-2 images so as to incorporate the parameter into improved agricultural efficiency plans.\n\n\nSatellite remote sensing informing evidence based action against forced labour camps: Boyd et al., 2018\nBoyd et al., 2018 use WorldView imagery available on Google Earth geobrowser to identify and estimate the number of brick kilns across the ‘Brick Belt’ that runs across south Asia - kilns which are known sites of modern day slavery.\n\n\nRemote sensing in movies\nAs a big movie fan, it felt only right to give Will Smith’s 1998 Enemy of the State a mention; a film which is an attempt (albeit incredibly over-the-top) the demonstrate the power of remote sensing and satellites. It’s a surveillance police state thriller which has all kinds of scenes which see satellite imagery used to track fugitives across the US.\n\n\nEstimating chlorophyll concentration in conifer needles: Moorthy et al., 2008\nNo longer is it impossible to find a needle in a haystack; Moorthy et al., 2008 were able to detect and measure the chlorophyll concentration in Jack Pine needles, a dominant Boreal forest species using Compact Airborne Spectrographic Imager (CASI) observations obtained in the visible-near infrared domain across 8 sites in Ontario, Canada.\n\n\nEstimating the phenological stages of oranges in Iranian orchards using remote sensing: Hashemi et al., 2021\nHashemi et al., 2021 looked to better constrain the growth of orange trees to improve agricultural models and production lines by utilising MODIS images to track the phenological stages of crops across the southeast of Fars Province in Iran.\n\n\nTracking pirates from space: Shortland, 2012\nPiracy off the shores of Somalia remains a significant issue; one which requires a land-based solution. Shortland, 2012 approaches this by suggesting a host of solutions, all of which use a variety of satellite remote sensing based methods. These look at both tracking ships remotely, as well as looking at night-time light data to pinpoint suspected beneficiaries of piracy ransom money.\n\n\nReducing traffic queue times using satellite imagery: Leitloff et al., 2007\nLeitloff et al., 2007 utilised the fine 1 metre resolution of QuickBird imagery to detect vehicle queues in urban areas to demonstrate the opportunities to use this information to reroute traffic and reduce queuing time.\n\n\nRemote sensors as an integral element of modern race car driving: Wojciechowski & Wojtowicz, 2023\nWojciechowski & Wojtowicz, 2023 describe the over 250 active remote sensors placed on Formula 1 cars during Grand Prix races that allow teams to generate over 500GB of data. Each sensor is assigned to one of three categories: control, instrumentation, and monitoring.\n\n\nAdvancements in remote sensing facilitating improved oil spill surveillance: Jha et al., 2008\nOil spill surveillance constitutes an important component of oil spill disaster management. Jha et al., 2008 reviewed the benefits of various remote sensors and satellites that are currently employed in surveillance efforts; an integral part of environmental management and industrial accountability.\n\n\nEstimation of tree cover using MODIS data at global, continental and regional/local scales: Hansen et al., 2005\nIt would be wrong to include anything other than trees for T, and Hansen et al., 2005 research which utilised MODIS data to map tree covers at different scales of study.\n\n\nManaging urbanisation using remote sensing: Rosni et al., 2016\nRosni et al., 2016 monitor urban sprawl across Kuala Lumpur metropolitan area using SPOT-5 images to demonstrate the rapid urbanisation rate affecting Indonesia.\n\n\nDetection of submerged ocean vessels using remote sensing techniques: Wren et al., 1997\nWren et al., 1997 described how remote sensing techniques can provide not only an aid but also a valuable alternative to approaches at detecting and recovering submerged vessels. Specifically, they identify the value of elevated sensors on Low Earth Orbit satellites as a powerful tool in reconnaissance missions.\n\n\nArchaeological attempts to identify ancient defence walls in China using remote sensing technology: Yue-ping & Lin, 2009\nSeveral studies have attempted to develop understandings of the structure and role of ancient defences walls in China, a key part of national defence history. Yue-ping & Lin, 2009 reviewed the use of these technologies in archeological work and describe how integral they are to contemporary digs.\n\n\nAttempts to measure xenophobia and global inequality: Mirza et al., 2021\nMirza et al., 2021 outline a novel methodology that seeks to quantify xenophobia and global inequality more broadly through remotely sensed data regarding average nighttime light emitted per person. They found a significant relationship between the resulting light-based inequality indicator and existing estimates of net income inequality.\n\n\nUsing USV to develop navigational and bathymetric charts of yacht ports: Specht et al., 2020\nSpecht et al., 2020 argue that modern yacht ports should primarily provide vessels with navigational safety associated with their maneuvering on the approach fairway. On this basis, they employ a methodology that uses an unnamed surface vehicle (USV) to aim to define and develop unique bathymetric and navigational charts of the harbor and the approach fairway.\n\n\nUsing satellite images to predict the effects of environmental change on zebra migration: Bartlam-Brooks et al., 2013\nHabitat loss in the Anthropocene has threatened historical zebra migrations. As a result, identifying and prioritizing migration routes for conservation has taken on a new urgency. In response to this, Bartlam-Brooks et al., 2013 utilised observations of precipitation from the Tropical Rainfall Measuring Mission data set and Moderate Resolution Imaging Spectroradiometer-derived normalized difference vegetation index (NDVI) to track daily zebra movements in Botswana.\n\n\n\nIn future weeks, I will focus on fewer studies and analyse them in greater depth. However for this week, I just wanted to read as much as possible and push the boat out in terms of what I knew and what was possible - so stay tuned!"
  },
  {
    "objectID": "week1.html#reflections",
    "href": "week1.html#reflections",
    "title": "1  Introduction to remote sensing",
    "section": "1.3 Reflections",
    "text": "1.3 Reflections\nI really enjoyed this introduction week! It was good to return to concepts I’d forgotten about since I last did any remote sensing and I particularly enjoyed playing around with SNAP in the practical. Not only was the process of making my summary sheet good fun (and a welcome respite from other writing/coding heavy assessments), but also a chance to remind myself of some key definitions. Specifically, I’d forgotten about all the different kinds of atmospheric corrections as in the past I’d applied mostly Raleigh corrections to data so that felt valuable ahead of week 3 which this week’s lecture mentioned would involve more information on. I also had a lot of fun pushing myself to comb through past literature and see the plethora of ways and contexts in which remote sensing data has been applied - I found the studies about adolescent behaviours, the egg industry and forced labour camps to be particularly fascinating. Whilst I have no doubt that in future weeks I will probably return to the comfort of exploring environmental applications of satellite data, this has sparked some ideas for potential topics to explore perhaps for the group project and I look forward to the rest of the course!"
  },
  {
    "objectID": "week1.html#references",
    "href": "week1.html#references",
    "title": "1  Introduction to remote sensing",
    "section": "1.4 References",
    "text": "1.4 References\n\nAhmed, W., Hossainy, S.J., Khaliduzzaman, A., Emmert, J.L., Kamruzzaman, M. (2023) ‘Non-destructive optical sensing technologies for advancing the egg industry toward Industry 4.0: A review’. Comprehensive Reviews in Food Science and Food Safety, vol. 22, is. 6, pp. 4378-4403\nAl-Joburi, K. (2017) ‘Integrating Remote Sensing and GIS for Mapping Garbage Dump Areas in the Kingdom of Bahrain’. Sustainable Civil Infrastructure (Book Series), pp. 262-271.\nBartlam-Brooks, H.L.A., Beck, P.S.A., Bohrer, G., Harris, S. (2013) ‘In search of greener pastures: Using satellite images to predict the effects of environmental change on zebra migration’. Journal of Geophysical Research: Biogeosciences, vol. 118, is. 4, pp. 1427-1437.\nBisrat, S.A., White, M.A., Beard, K.H., Cutler, D.R. (2011) ‘Predicting the distribution potential of an invasive frog using remotely sensed data in Hawaii’, Diversity and Distributions, vol. 18, is. 7, pp. 648-660.\nBoyd, D.S., Jackson, B., Wardlaw, J., Foody, G.M., Marsh, S., Bales, K. (2018) ‘Slavery from Space: Demonstrating the role for satellite remote sensing to inform evidence-based action related to UN SDG number 8’. ISPRS Journal of Photogrammetry and Remote Sensing, vol. 142, pp. 380-388.\nDorneles, M.M., Brito, G.H.M., Rocha, I.J.D.F., Alves, S.M.D.F. (2023) ‘Sentinel image to estimate industrial tomato Leaf Area Index’. Brazilian Archives of Biology and Technology, vol. 66.\nHansen, M.C., Townshend, J.R.G., DeFries, R.S., Carroll, M. (2007) ‘Estimation of tree cover using MODIS data at global, continental and regional/local scales’. International Journal of Remote Sensing, vol. 26, is. 19, pp. 4359-4380\nHashemi, A., Yazdanpanah, H., Momeni, M. (2021) ‘Estimating the Main Phenological Stages of Orange Tree Using Remote Sensing (Case Study: Southeast Orchards of Fars Province in Iran)’. Geography and Environmental Planning, vol. 32, is. 2, pp. 119-134.\nHerridge-Berry, S., Brown, C.M., Peddle, D.R., Pickles, B.J., Coburn, C.A. (2021) ‘Dinosaur fossil discovery using remotely piloted aircraft systems and spectral mixture analysis’. Canadian Society of Vertebrate Palaeontology, vol 9, pp. 1-39.\nJanssen, M.A., Hofstadter, M.D., Gulkis, S., Ingersoll, A.P., Allison, M., Bolton, S.J., Levin, S.M., Kamp, L.W. (2005) ‘Microwave remote sensing of Jupiter’s atmosphere from an orbiting spacecraft’. Icarus, vol. 173, is. 2, pp. 447-453.\nJha, M.N., Levy, J., Gao, Y. (2008) ‘Advances in Remote Sensing for Oil Spill Disaster Management: State-of-the-Art Sensors Technology for Oil Spill Surveillance’. Sensors for Disaster and Emergency Management Decision Making, vol. 8, is. 1, pp. 236-255.\nKranenburg, R.F., Ou, F., Sevo, P., Petruzzella, M., Ridder, R., van Klinken, A., Hakkel, K.D., van Elst, D.M.J., van Veldhoven, R., Pagliano, F., van Asten, A.C., Fiore, A. (2022) ‘On-site illicit-drug detection with an integrated near-infrared spectral sensor: A proof of concept’. Talanta, vol. 245.\nLeitloff, J., Hinz, S., Stilla, U. (2007) ‘Vehicle queue detection in satellite images of urban areas’. DigitalGlobe, pp. 1-5.\nMirza, M.U., Xu, C., van Bavel, B., van Nes, E.H., Scheffer, M. (2021) ‘Global inequality remotely sensed’. PNAS Economic Sciences, vol. 118, is. 18.\nMoorthy, I., Miller, J.R., Noland, T.L. (2008) ‘Estimating chlorophyll concentration in conifer needles with hyperspectral data: An assessment at the needle and canopy level’. Remote Sensing of Environment, vol. 112, is. 6, pp. 2824-2838.\nPlaner-Friedrich, B., Becker, J., Brimer, B., Merkel, B.J. (2008) ‘Low‐cost aerial photography for high‐resolution mapping of hydrothermal areas in Yellowstone National Park’. International Journal of Remote Sensing, vol. 29, is. 6, pp. 1781-1794.\nShortland, A. (2012) ‘Treasure mapped: Using satellite imagery to track the developmental effects of Somali Piracy’. Africa Programme Paper, AFP PP 2012/01\nSpecht, M., Specht, C., Szafran, M., Makar, A., Dabrowski, P., Lasota, H., Cywinski, P. (2020) ‘The Use of USV to Develop Navigational and Bathymetric Charts of Yacht Ports on the Example of National Sailing Centre in Gdańsk’. Remote Sensing, vol. 12, is. 16.\nStefański, P., Jach, T., Kozak, J. (2023) ‘Classification of punches in Olympic boxing using static RGB cameras’. Computational Collective Intelligence, pp. 540-551\nToharudin, T., Caraka, R.E., Kaban, P.A., Kim, Y., Kurniawan, R., Supardi, K., Mufti, S.A., Gio, P.U., Sakti, A.D., Chen, R.C., Noh, M., Pardamean, B. (2024) ‘Investigating Adolescent Vulnerability in Indonesia: A Socio-Remote Sensing Big Data Analytics Study Using Night Light Data’. IEEE Access, vol. 10\nVarela-Jaramillo, A., Rivas-Torres, G., Guayasamin, J.M., Steinfartz, S., MacLeod, A. (2023) ‘A pilot study to estimate the population size of endangered Galápagos marine iguanas using drones’\nWojciechowski, P., Wojtowicz, K. (2023) ‘Challenges in designing measurement systems for Formula One cars’. IEEE International Workshop on Metrology for Automotive (MetroAutomotive), pp. 57-61\nWren, G.G., May, D. (1997) ‘Detection of submerged vessels using remote sensing techniques’. Australian Defence Force Journal, pp. 7-15.\nYue-Ping, N., Lin, Y. (2009) ‘Applications and development of arcaeological remote sensing technology in China’. Journal of Remote Sensing, pp. 940-961"
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Xaringan",
    "section": "",
    "text": "This week we were tasked with familiarising ourselves with Xaringan and Quarto, neither of which I have ever come across before. For my presentation, I decided to return to my cryospheric roots by researching ICESat-2, a lidar satellite I’ve briefly used during my undergraduate degree and have seen mentioned in many a paper. A summary of the sensor, a brief foray into its published applications and a reflection on its contributions are outlined in the Xaringan presentation embedded below."
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThis week’s lecture was very content heavy, so to summarise I decided to create a road map that outlines the content covered following the path the lecture took - this is pictured below!\n\n\n\nWeek 3 lecture ‘road map’. Image available on GitHub here.\n\n\nOne thing that really piqued my curiosity during the lecture was the mention of Virginia Norwood and her pioneering Landsat work. Very infrequently do I hear mention of female scientists so I always find it exciting to learn more about their work and role in scientific history. In one obituary I found this snippet to be particularly amusing. The article discusses how many scientists within the NASA x Geological Survey team were skeptical that her multispectral scanner invention would work, believing it to be too clunky and inefficient. Upon it proving to work and Landsat’s subsequent send-off into space, a geologist who was vocally skeptical of the technology was recorded saying “I was so wrong about this. I’m not going to eat crow. Not big enough. I’m going to eat raven.”. \n\n\n\nNorwood amongst her colleagues at NASA (Source: NASA Goddard)\n\n\nThat comment, along with the photo of her at work surrounded by a group of male scientists (above) really resonated with me. I highly recommend reading this obituary (linked below), as it details the lifetime of gender-based obstacles she faced. Norwood really seems like a legend. \nVirginia Norwood New York Times obituary (2023)"
  },
  {
    "objectID": "week3.html#applications",
    "href": "week3.html#applications",
    "title": "3  Corrections",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nThere is a lot that could be potentially investigated in-depth from this week’s lecture, so to narrow down the task I decided to focus my research on band ratioing as this is a technique I’ve used fairly extensively in the past and find most interesting. Specifically, I wanted to return to a paper that I discovered during my undergraduate degree which inspired me greatly and consider the methods employed in their research in the context of this week’s taught content.\n\n3.2.1 Band ratio: a closer look\nAs defined by Shahi et al., (2023) in their review of remote sensing methods, band ratioing is ‘a technique in which DN values in one spectral band is divided from the corresponding values in another band’, creating an output known as a ‘ratioed image’ or simply the band ratio. This technique enhances spectral characteristics of specific features in an image, regardless of variation in scene illumination. It is often used for change detection when applied to multitemporal data and has been used in contexts of deforestation, hydrology, agriculture, cryosphere monitoring among others. \nProbably the most commonly used band ratio is NDVI, the Normalised Difference Vegetation Index. This index is computed as the difference between near-infrared (NIR) and red reflectance divided by their sum (Gessesse et al., 2019). It is represented by the following formula: \n\nLow NDVI values indicate moisture-stressed vegetation whilst higher values indicate a higher density of green vegetation, as represented in the diagram below.\n\n\n\nNDVI diagram. Source: EOS Data Analytics, 2019\n\n\nAs mentioned above, most uses of NDVI that I found across past literature are in the context of deforestation (EG. Othman et al., 2018 in Malaysia, Muñoz Peña et al., 2015 in Peru, Ngigi et al., 2004 in Kenya etc.) and have demonstrated the power of using band ratioing to monitor landscape change over time. However, uses of NDVI have not been limited to forested regions. \n\n\n3.2.2 Antarctica going green\nDuring my undergraduate degree I was lucky enough to attend a lecture delivered by Dr Andrew Gray, a glacial biogeochemist specialising in the use of remote sensing to monitor polar environments. Until this point I had been exposed to NDVI several times (predominantly in the context of monitoring Scottish forests), but never beyond this. In Andrew’s talk he explained the research he was doing in Antarctica studying seasonal recurrent algal blooming that was transforming the otherwise white swathes of ice into multicoloured landscapes. In his research, he sought to monitor these blooms - believed to be lowering the surface albedo and thus contributing significantly to glacial ablation - by collecting spectral measurements during fieldwork in Antarctica and relating these to satellite imagery back in the lab. \n\n\n\n50m x 100m green snow algal bloom in Antarctica. Source: Gray et al. 2020\n\n\nThis research was published in his jointly authored 2020 paper, in which he describes the correction and image enhancement methods that were used - all of which were mentioned in this week’s taught content. These include orthorectification, atmospheric correction, masking and filtering as well as the application of band math. Finally, to identify algae across the ice they used used the spectral measurements obtained in the field and compared these with the NDVI results from band ratioing of the Sentinel-2 imagery used to estimate algal bloom coverage. Their research identified 1679 individual blooms, averaging 1043 m2, but spanning 300 m2 to 145,000m2. Moreover, they estimated the carbon content of these blooms to be equivalent to 479 tonnes of carbon within a growth season. \n\n\n\nOverview of the locations of individual blooms of green-dominant snow algae identified across the Antarctic Peninsula using modelled data from satellite imagery and ground data. Source: Gray et al., 2020\n\n\nI found it really interesting to learn about how NDVI could be applied in polar regions and was encouraged by the success of this study! It definitely doesn’t appear at first thought to be a technique that has any use in the polar regions where vegetation is minimal if present at all, which is probably why it stuck with me since my first reading. This technique cannot be endlessly praised however, as Gray et al., 2020 note problems in the use of NDVI to identify red algae in this paper - they attributed this to limited band sensitivity that hindered the detection of red algae. Ultimately, this means that the number of blooms that they were able to identify was not representative of all blooms, but rather specifically green algal blooms. Whilst I don’t think the authors necessarily tried to hide this shortcoming within the paper, I do think that the abstract glosses over this outcome in the abstract which implies that all snow algae is accounted for in the study (“This increase is predicted to outweigh biomass lost from small islands, resulting in a net increase in snow algae extent and biomass as the Peninsula warms”). If anything, I wish the fact that only green algae was mapped in this study to enhance the point that algae is extensive across the Antarctic peninsula!\nI was encouraged to see however that their issues regarding red snow algae detection were addressed in a paper published the following year by Gray et al., 2021, in which they applied NDVI to WorldView imagery that, after performing a spectral angle mapper classification in ENVI had better sensitivity to red algae than the Sentinel-2 imagery used in their original 2020 study. This methodology returned greater results as all algae species were able to be detected (see below).\n\n\n\nMapped red and green snow algal distribution and modelled cell density obtained through NDVI + field data across Anchorage Island, Antarctica. Source: Gray et al., 2021\n\n\nMoving on from NDVI, one additional thing that came up in my re-reading of Gray’s research that I was reminded of during this week’s lecture was the radiative transfer model he used to perform atmospheric correction in his research. Before this point, I knew that atmospheric correction was essential, but understood little about the mechanisms by which it worked let alone the variety of models that exist to perform corrections. I discovered that almost all quality models (EG. 6S, FLAASH, MODTRAN, ACOLITE etc.) are incredibly expensive and of the freely available models (Sen2Cor for S2 data, Py6S and a personal enemy of mine, iCOR which refuses to work on SNAP without crashing) none are particularly user-friendly or of a high quality. This is unfortunate given the free availability of quality imagery and represents to me a significant issue existing in the remote sensing world. It would be nice to see either improved compatibility between freely available models and GIS programmes or a reduction in the cost of quality models. It would also be great to see more models develop specifically for compatibility with Google Earth Engine as I believe this to be a key player in the future of remote sensing. \nSince my initial introduction to the use of band ratios in cryosphere research 2022, I was pleased to see the number of studies that have continued to use NDVIs to monitor vegetation (EG. Carlson et al., 2023, Fonesca et al., 2023, Cannone et al., 2023). Whilst this is a positive thing, I do think that these studies in future could improve their means of testing the accuracy of their algae detection. Currently, the above studies all rely quite heavily on in situ spectral sampling but due to site accessibility issues the number of sample points is limited. I have no idea what an alternative could be, but increased attention on this issue would be valuable."
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nIt was fun to think back on past work I’d read and undertaken myself this week, as I hadn’t thought much about image processing since April 2023. Although I pretty much entirely focused on band ratioing (and mentioned atmospheric correction briefly) in this diary entry, I also found it useful this week to be reminded of image enhancement techniques.\nIn particular, I’d forgotten about Principal Component Analysis, a technique which I’m sure in future I will need to use. I hadn’t realised until this week how easy R Studio made it to perform PCA using the prcomp() function in the terra package; something which I want to make a note of here so I don’t forget. Moreover, it was useful to be explained texture analysis properly as before this week I had never formally come across it. I ended up having an interesting conversation about it with my flatmate who’s training to become a radiologist and had no idea how involved it was in medical practice - I’d only ever thought about it before in the context of remote sensing! \nWhilst I didn’t give the practicals as much time as I would’ve liked to this week due to other assessments being due (and my fear of the long processing times involved in performing techniques like PCA), I enjoyed looking through the code provided in the notes and have no doubt that I will be returning to this in future when I conduct research of my own. I must say though, having processed satellite imagery on SNAP/ENVI/R Studio versus Google Earth Engine, I feel grateful to be studying at a time of growing cloud computing as I find GEE much easier to use - this has me really excited for week 5!"
  },
  {
    "objectID": "week3.html#references",
    "href": "week3.html#references",
    "title": "3  Corrections",
    "section": "3.4 References",
    "text": "3.4 References\n\nCannone, N., Guglielmin, M., Ponti, S. (2023) ‘Suitability and limitations of ground-based imagery and thermography for long-term monitoring of vegetation changes in Victoria Land (continental Antarctica)’. Ecological Indicators, vol. 156.\nCarlson, D.F., Vivó-Pons, A., Treier, U.A., Mätzler, E., Meire, L., Sejr, M., Krause-Jensen, D. (2023) ‘Mapping intertidal macrophytes in fjords in Southwest Greenland using Sentinel-2 imagery’. Science of the Total Environment, vol. 865. \nEOS Data Analytics (2019) ‘NDVI FAQ: All you need to know about index’. Web article, available at: https://eos.com/blog/ndvi-faq-all-you-need-to-know-about-ndvi/\nFonesca, E.L., Santos, E.C., Figueiredo, A.R., Simões, J.C. (2023) ‘The use of Sentinel-2 imagery to generate vegetation maps for the Northern Antarctic Peninsula and offshore islands’. Anais da Academia Brasileira de Ciências, vol. 95. \nGessesse, A.M., Melesse, A.M. (2019) ‘Chapter 8: Temporal relationships between time series CHIRPS-rainfall estimation and eMODIS-NDVI satellite images in Amhara Region, Ethiopia’, in (ed.) Melesse, A. M., Abtew, W., Senay, G. Extreme Hydrology and Climate Variability. Elsevier: London.\nGray, A., Krolikowski, M., Fretwell, P., Convey, P., Peck, L.S., Mendelova, M., Smith, A.G., Davey, M.P. (2020) ‘Remote sensing reveals Antarctic green snow algae as important terrestrial carbon sink’. Nature Communications, vol. 11, no. 2527.\nGray, A., Krolikowski, M., Fretwell, P., Convey, P., Peck, L.S., Mendelova, M., Smith, A.G., Davey, M.P. (2021) ‘Remote sensing phenology of Antarctic green and red snow algae using WorldView satellites’. Frontiers in Plant Science, vol. 12.\nMcClain, D.L. (2023) ‘Virginia Norwood, ’Mother’ of Satellite Imaging Systems, Dies at 96’. Web article, available at: https://www.nytimes.com/2023/04/12/science/space/virginia-norwood-dead.html\nMuñoz Peña, M.A., Navarro, F.A.R., (2015) ‘An NDVI-data harmonic analysis to study deforestation in Peru’s Tahuamanu province during 2001-2011’. International Journal of Remote Sensing, vol. 37, is. 4, pp. 856-875.\nNgigi, T.G., Tateishi, R. (2004) ‘Monitoring deforestation in Kenya’. International Journal of Environmental Studies, vol. 61, is. 3, pp. 281-291.\nOthman, M.A., Ash’aari, Z.H., Aris, A.Z., Ramli, M.F. (2018) ‘Tropical deforestation monitoring using NDVI from MODIS satellite: a case study in Pahang, Malaysia’. IOP Conference Series: Earth and Environmental Science, vol. 169\nShahi, A.P., Rai, P.K., Islam, R., Mishra, V.N. (2023) ‘Chapter 5 - Remote sensing data extraction and inversion techniques: A review’ in (ed.) Singh, A.K., Tiwai, S. Atmospheric Remote Sensing. Elsevier: London."
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "4  Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\n\n4.1.1 Nairobi, Kenya; the rapidly urbanising ‘Silicon-Savannah’\nNairobi is the capital and largest city in Kenya, containing a current population of nearly 4.5 million (Hey, 2023).\n\n\n\nAerial image of Nairobi, Kenya (2016). Source: Landsat-8, NASA\n\n\nLike many cities in Africa, Nairobi has experienced unprecedented urbanisation in the 21st century which has triggered many positive consequences including a rapidly expanding economy (particularly driven by an explosion in the city’s tech industry earning Nairobi the nickname ‘Silicon-Savannah’), economic advancement and growing global influence (UN Habitat, 2006, Switzerland Global Enterprise, 2021). Simultaneously however, uncontrolled urbanisation has also triggered a host of new socio-economic and environmental challenges that have posed (among many things) a serious strain on existing infrastructure, a reduction in environmental quality and record-high unemployment (Nato et al., 2023).\nOf the negative consequences brought about by urbanisation, air quality in Nairobi has experienced perhaps the greatest hit, representing a serious environmental challenge that is only set to worsen with forecasted population growth.\n\n\n4.1.2 Air quality degradation: causes, consequences and challenges\nIn 2019, air pollution in Nairobi was 4.2 times higher than WHO recommended average annual concentration levels; an achievement which has been consistently reported since 2001 (Clean Air Fund, 2023, ASAP Report, 2019). This is result of both formal and informal activities, with the three largest sectoral contributors being road transport, solid waste mismanagement and biomass fuels (see pie chart below for full breakdown).\n\n\n\nPM2.5 Exposure estimates by sectoral source contributors. Source: McDuffie et al. 2021 via Clean Air Fund, 2023\n\n\nCurrently, the city only has one active air pollution monitoring site (located near Jomo Kenyatta airport) which limits opportunities to conduct spatio-temporal analyses of air pollution and instead forces a dependence on short term, ad hoc monitoring studies (Kinney et al.,2012, Nairobi City Council, 2018). Despite a lack of records however, the effects of pollution have not gone unnoticed. Both short and long term respiratory illnesses including pneumonia and lung cancer represent significant public health problems, with three in every ten hospital visits in the capital being attributed to respiratory infections linked to air pollution (Briton, 2023).\nThe Kenyan national government sought to respond to this by developing strict Air Quality Regulations for the country in 2014. However, high levels of governmental corruption and financial mismanagement saw little implementation of these regulations and instead the document became used for referencing purposes (ASAP Report, 2019). It was evident that city councilors alone would struggle to implement action, and that international cooperation was necessary for instigating change. It was in this landscape that the 2019 Air Quality Action Plan was announced; an ambitious collaboration between the Kenyan national government, the UN Environment Agency and the Environmental Compliance Institute.\n\n\n4.1.3 The Air Quality Action Plan (2019-2023)\nThis plan seeks to support Nairobi City County to develop better air quality management strategies, with the overall objective of building improved capacity to develop, implement and enforce policy and regulatory frameworks for air quality management across the capital (Nairobi City Council, 2018). The fixed time period for this plan is 2019-2023, however it was hoped that following the official action ‘end date’ that objectives would remain a top governmental priority. The plan has four main objectives, detailed in the table below.\n\nBroadly, these aims can be put in 3 overarching categories:\n\n\n\n\n\n\nObjective\nStrategy\n\n\n\n\n\nBuild scientific evidence for policy/legislative interventions for air quality management\n\nUndertake an inventory of the air pollutants and emission sources that most contribute to poor air quality in Nairobi City\n\n\n\nRaise public awareness on the health/environmental impacts of air pollution\n\nDeploy effective communication on the health and environmental impacts of air pollution, mitigation options and benefits\n\n\n\nDevelop effective approaches for air quality management\n\nAdopt policy, legislative and regulatory options for air management that incorporate mandatory requirements, voluntary and market based approaches\n\n\n\nBuild an effective implementation/enforcement programme for air quality legislation\n\nEnhance the capacity of NCCG for implementation and enforcement programme for Nairobi City’s air quality legislation\n\n\n\n\nImproving current monitoring capacity\nEducation\nImplementation/enforcement\n\nThese objectives are closely linked to several of the UN Sustainable Development Goals, the most relevant of which are presented in the figure below. Specifically, Nairobi’s Action Plan mirrors the aim outlined in Target 3.9 under Goal 3 which focuses on reducing the number of deaths and illnesses from hazardous chemicals and air, water, and soil pollution and contamination.\n\n\n\nRelevant UN Sustainable Development Goals. Source: UN SDGs\n\n\nWhilst the action plan demonstrated a growing concern towards air quality and an escalated government focus on pollution, the objectives have not been addressed with equal success. The ASAP briefing (led by the UK Government) found approaches to traffic management and reducing emissions by cars to be effective and multifaceted, with implementation plans scheduled for the present decade (ASAP Report, 2019). Similarly, outreach and education programs appear to have had a degree of success as indicated in studies such as that by Kamau, 2016. By contrast however, less attention was given to reducing pollution caused by poor waste management and the burning of waste (both in residential areas and in the city’s main rubbish dump, Dandora Landfill) remains a pressing problem.\nThat the action plan has thus far failed to address this problem of waste management, despite it being a major source of pollutants demonstrates the necessity for new suggested approaches to tackle the problem. Currently, there is no information online about how the city seeks to tackle this problem beyond issuing penalties to those caught in the act of burning, which in itself is a rarely utilised approach (Kamau, 2016). In the following section I shall outline a method which relies on freely available EO data to address this; a method which I believe, if implemented, could offer an effective and low-cost solution to the current problem reported across Nairobi."
  },
  {
    "objectID": "week4.html#applications",
    "href": "week4.html#applications",
    "title": "4  Policy",
    "section": "4.2 Applications",
    "text": "4.2 Applications\n\n4.2.1 Waste management and illegal burning: the problem\nA serious problem in Nairobi is the illegal dumping and burning of waste. Every day, the city generates 3000 tonnes of solid municipal waste, of which 62% is illegally disposed of (dumped on the side of the road + burnt). This generates an estimated 25% of Nairobi’s PM2.5 concentrations and thus represents a key source of air pollutants. Further information on this problem can be found here: City residents’ lives at risk over open burning of waste\n\n\n\nSource: Limo/Tearfund for The Guardian, 2023\n\n\nCurrently, local authorities are charged with the responsibility of collecting and disposing of solid municipal waste within their area of jurisdiction, and are granted powers to issue minimum fines of KSH 500,000 ($3,500) or imprison offenders by up to 6 months. Presently however, rubbish collection is extremely poor, with many areas never being served or only once in several months (Muniafu & Otiato, 2010). This is attributed to failings by government authorities above local councilors to monitor and enforce waste management responsibilities; a case which is worsened by severe financial mismanagement (Henry et al., 2006). To take matters into their own hands, many individuals in residential areas move waste to the roadside and burn it, producing clouds of toxic noxious fumes (Muniafu & Otiato, 2010).\n\n\n4.2.2 Waste management and illegal burning: the proposed solution\nGiven the evident legal loopholes and broken accountability system for waste in the city, I suggest that the problem could be best addressed through the creation of an impartial watchdog body who monitor the location of burnt waste through satellite imagery. Instead of penalising individuals who resort to burning waste as a last-ditch scenario when local authorities fail to do their job, this watchdog could report its findings to the national government and identify which local authorities have the worst performance in regards to waste removal.\nThe idea for this came from my knowledge of past studies that utilise a Normalised Burn Ratio Index to monitor the severity of (typically) forest fires (EG. Lu et al.,2015 Giddey et al., 2022, Alcaras et al., 2022). These papers used freely available satellite imagery (EG. Sentinel-2) to derive an index for fire severity that allows the location and intensity of fires to be mapped. This served as inspiration for me as it demonstrated the potential for methodologies to monitor fire using remote sensing to be employed even where budgets for accessing expensive high spectral/spatial/temporal imagery do not exist. From this starting point, I began to investigate whether similar methods had been employed in the detection of illegal fires/burning.\nI found Nádudvari et al.’s 2021 paper to be valuable in considering viable methodologies. They were able to identify the location of self-heating coal waste (a precursor to coal dump fires) in Polish and Ukranian mining regions by creating a self heating intensity index that used band math on selected cloud-free Landsat images. The full details of their methodology are outlined in section 3.1 of the paper: Classification of fires in coal waste dumps based on Landsat, Aster thermal bands and thermal camera in Polish and Ukrainian mining regions but broadly, the study depended on the thermal infrared sensors of satellite images taken by Landsat and applied ASTER, ‘the cost-effective and time-saving technique for monitoring coal waste fires and detecting their thermal anomalies’.\n\n\n\n‘Three representative coal waste dumps as examples of how the SHII index was calculated’. Source: Nádudvari et al., 2021\n\n\nAlthough the limitations of their method are described in the paper (namely, they tried to use a combination of images obtained by different Landsat satellites which led to issues when comparing images against one another), they found Landsat 7 ETM+ to be the most effective sensor for their purposes. This is valuable insight in regards to opportunities for remote sensing in Nairobi as attempts to monitor fires could start by applying a similar methodology on imagery obtained by just this sensor. However, most waste burning occurs at night time in Nairobi to avoid detection (Clean Air Fund, 2023), and given that night-time Landsat images are rare (Nádudvari et al., 2021), this method may require supplementation by images that are obtained at night - in their case, they did this by using capturing images using a drone at night.\nA more sophisticated methodology for detecting waste burning (as well as illegal dumping more generally) was outlined in a proof-of-concept article by The California Integrated Waste Management Board (CIWMB, 2005). They were able to identify the location of illegal waste tire piles by using high spatial resolution satellite imagery (Multispectral Ikonos) across 4 small areas with a combined area of &gt;50km2 in California. Their method involved the use of visual analysis and an automated Tire Identification from Reflectance (TIRe) model to find possible waste tire piles - the model was a univariate decision tree which used the spectral characteristics of tires to segment possible tire features from the remaining image. The model was successful, proving capable of identifying 15 tire piles (2 of which were previously unknown to the CIWMB) and returning only one false positive. Unlike the research by Nádudvari, the CIWMB paper demonstrated the opportunity to identify much smaller objects from satellite data. However, whilst Landsat data is freely available, Ikonos sits behind a pay wall, which may affect the feasibility of its use in the case of Nairobi where government budgets are stretched and misused. Nonetheless, CIWMD’s findings demonstrate a proven, alternative approach to identifying waste + burning using remote sensing data which could be adapted for use by the Nairobi government.\nA final approach which has been outlined in past literature was developed by Scott et al.,2023, who identified instances of illegal waste burning in the Maldieves through the development of a machine learning approach. Specifically, they used an ‘image classification and semantic segmentation model based on a pretrained convolutional neural network to identify and locate plumes within images’. They fed three-band (RGB), 3m/pixel images from Planet satellites into their model and found their classification model to achieve a training accuracy of 96% and a validation accuracy of 83%. Scott’s research indicates ever-expanding opportunities to utilise new technologies to detect fires more accurately than ever before.\n\n\n\nSuccessful model outputs versus visually identified plumes. Source: Scott et al. 2023\n\n\nOf the three methods outlined in this section, Scott et al.,’s 2023 represents the most complex. Unlike Nádudvari et al.’s 2021 paper, opportunities to reproduce Scott et al.,’s work is potentially more limited as it would require a greater technological capacity and people knowledgeable in the use of machine learning - several parts of the methodology went over my head! That isn’t to say it cannot be used - if funding was available and specialists were employed, this method would be an incredibly valuable way of monitoring burnt waste across Nairobi. However, as mentioned previously, it is unclear as to whether this is feasible given financial constraints. Therefore, in an ideal world it would be great to see a methodology like that used by Scott et al., 2023 to identifying poor waste management in local authorities across Nairobi, but it may be that an approach like that used by Nádudvari et al., 2021 or CIWMB, 2005 is more suitable.\nIt is important to note that these papers represent just three ways of identifying waste mismanagement contributing to air pollution from satellite imagery - other methodologies are outlined elsewhere! Instead of outlining a singular method, I hope this section has effectively communicated the fact that there is a wide range of ways of monitoring this pollution-contributor; each with a range of pros and cons."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nBefore settling on Nairobi’s Air Quality Action Plan I did quite a lot of preliminary research into different metropolitan development plans and had no idea quite how many there were. Coming from a strictly quantitative physical geography background I had never really researched urban development before and found it particularly surprising to see how many frameworks overlapped with one another on spatial and temporal scales. If I’m being honest, this made me feel quite disillusioned with the idea that many of them are actually effective; I’m sure this is quite a generic realisation, but one which took me this long to come to. Another thing that I noticed was how wildly varied the quality of plans could be - comparing Nairobi’s lackluster Air Quality plan to something detailed and solution-focused like the Ahmedabad Heat-Health Action Plan (Knowlton et al.,2014) was valuable in demonstrating what makes a framework useful in practice rather than just serving as a reference document. It was probably from this realisation that I became so invested in the week’s task; I really enjoyed the creativity that had to go into imagining usable and actionable solutions to recognised problems. It was particularly satisfying to come up with ideas that involved the use of EO data, only to find that similar research had been conducted elsewhere that found the methods to be viable and effective. I really experienced this when I came across Scott et al.,’s 2023 paper in the Maldives as this was the idea I had been skirting around when reading other papers.\nBeyond my personal reflections, I also want to add some reflections on the case of Nairobi itself. Although I do think that my proposed solutions could be theoretically used to accomplish some of the objectives outlined the city’s Action Plan, I’m also conscious of the fact that they’re incredibly ambitious and probably unrealistic. This is not due to limitiations in methodologies or data availability; rather, in virtually all of the literature I read I was constantly reminded of the corruption and financial mismanagement that plagues not only Nairobi but all levels of Kenya’s systems of governance. Therefore whilst it is totally feasible that a watchdog is set up and EO data is used for monitoring, I’m not sure that the resulting findings would do much to crack down on those responsible for air pollution. Instead, I fear that it would serve as another financial drain. Hopefully this is just my pessimism talking, as I would love to see novel uses of EO data outlined in scientific papers be used in practice to enact change."
  },
  {
    "objectID": "week4.html#references",
    "href": "week4.html#references",
    "title": "4  Policy",
    "section": "4.4 References",
    "text": "4.4 References\n\nAlcaras, E., Costantino, D., Guastaferro, F., Parente, C., Pepe, M. (2022) ‘Normalised burn ratio plus (NBR+): A new index for Sentinel-2 imagery’. Remote Sensing, vol. 14, is. 7.\nASAP Report (2019) ‘Air quality briefing note: Nairobi (Kenya)’. Available at: https://assets.publishing.service.gov.uk/media/5eb16f4b86650c4353446282/ASAP_-_East_Africa_-_Air_Quality_Briefing_Note_-_Nairobi.pdf\nBriton, G. (2023) ‘Kenya: Air pollution-related diseases burdening healthcare in Nairobi’. Web article, available at: https://news.scienceafrica.co.ke/kenya-air-pollution-related-diseases-burdening-healthcare-in-nairobi/\nCalifornia Integrated Waste Management Board (CIWMB) (2005) ‘Waste Tire Hauling and Disposal’. Available at:http://www.calrecycle.ca.gov/ Tires/Fires/\nClean Air Fund (2023) ‘Nairobi and air pollution’. Web article, available at: https://www.cleanairfund.org/clean-air-africas-cities/nairobi-and-air-pollution/\nGiddey, B.J., Baard, J.A., Kraaij, T. (2022) ‘Verification of the differened Normalised Burn Ratio (dNBR) as an index of fire severity in Afrotemperate Forest’. South African Journal of Botany, vol. 146, pp. 348-353.\nHenry, R.K., Yongsheng, Z., Jun, D. (2006) ‘Municipal solid waste management challenges in developing countries - Kenyan case study’. Waste Management, vol. 26, is. 1, pp. 92-100.\nHey, J.V. (2023) ‘Improving air quality in Nairobi’. Web article, available at: https://le.ac.uk/research/stories/sustaining-world/air-quality-nairobi\nKamau, I.S. (2016) ‘Actors in environmental crime in city slums of Kenya; the case of illegal dumping in Mathare slum of Nairobi’. University of Nairobi Press.\nKinney, P.L., Gichuru, M.G., Volavka-Close, N., Ngo, N., Ndiba, P.K., Law, A., Gachanja, A., Gaita, S.M., Chillrud, S.N., Sclar, E. (2012) ‘Traffic impacts on PM2.5 air quality in Nairobi, Kenya’. Environment, Science, Policy, vol. 14, is. 4, pp. 369-378.\nKnowlton, K., Kulkarni, S.P., Azhar, G.S., Mavalankar, D., Jaiswal, A., Connolly, M., Nori-Sarma, A., Rajiva, A., Dutta, P., Deol, B., Sanchez, L., Khosla, R., Webster, P.J., Toma, V.E., Sheffield, P., Hess, J.J. (2014) ‘Development and implementation of South Asia’s first heat-health action plan in Ahmedabad (Gujarat, India)’. International Journal of Environmental Research and Public Health, vol. 11, is. 4, pp. 3473-3492.\nLu, B., He, Y., Tong, A. (2015) ‘Evaluation of spectral indices for estimating burn severity in semiarid grasslands’. International Journal of Wildland Fire, vol. 25, is. 2, pp. 147-157\nMuniafu, M., Otiato, E. (2010) ‘Solid waste management in Nairobi, Kenya. A case for emerging economies’. The Journal of Language, Technology & Entrepreneurship in Africa, vol. 2, no. 1, pp. 342-350\nNádudvari, Á, Abramowicz, A., Fabiańska, M., Misz-Kennan, M., Ciesielczuk, J. (2021) ‘Classification of fires in coal waste dumps based on Landsat, ASTER thermal bands and thermal cameras in Polish and Ukranian mining regions’. International Journal of Coal Science and Technology, vol. 8, pp. 441-456.\nNairobi City Council (2018) ‘Air quality action plan’. Available at: https://www.eci-africa.org/wp-content/uploads/2019/05/Nairobi-Air-Quality-Action-Plan_Final_ECI_31.12.2018.pdf\nNASA (2016) ‘Nairobi swells with urban growth’. Web article, available at: https://earthobservatory.nasa.gov/images/88822/nairobi-swells-with-urban-growth\nNato, J., Njogu, H., Ngugi, R., Ordu, A.U., Ijjasz-Vasquez, E. (2023) ‘Urban economic development in Africa: A case study of Nairobi city’. Web article, available at: https://www.brookings.edu/articles/urban-economic-development-in-africa-a-case-study-of-nairobi-city/\nScott, S.R., Hailemariam, P.E., Bhave, P.V., Bergin, M.H., Carlson, D.E. (2023) ‘Identifying waste burning plumes using high-resolution satellite imagery and machine learning: a case study in the Maldieves’. Environment, Science and Technology Letters, vol. 10, is. 8, pp. 642-648.\nSwitzerland Global Enterprise (2021) ‘Global opportunities: Silicon Savannah - Tapping into the potential of Africa’s tech hub’. Web article, available at: https://www.s-ge.com/en/article/global-opportunities/20213-c6-kenya-tech-hub-fint1?ct\nThe Guardian (2023) ‘The waste pickers of Nairobi’s Dandora dump site - in pictures’. Web article, available at: https://www.theguardian.com/environment/gallery/2023/nov/17/waste-pickers-nairobi-dandora-dump-site-in-pictures\nUN Habitat (2006) ‘Nairobi Urban Sector Profile’. Available at: https://unhabitat.org/sites/default/files/download-manager-files/Kenya%20Nairobi%20Urban%20Profile.pdf"
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nThis week we were formally introduced to Google Earth Engine (hereafter GEE), with the taught content being split into two parts:\n\nThe set up of GEE\nHow GEE is used\n\nAs I have experience using GEE at work, I won’t cover the basics too thoroughly. The main takeaway is that GEE supports geospatial analysis at a range of scales; at great speed, across the world, and through an enormous range of data sets and types.\nImportantly, unlike other programmes that we have been taught, GEE uses Javascript (whilst a Python API exists in GEE it’s a bit janky and Java is just easier to use). As a result, the coding syntax is ever so slightly different (EG. Variables are defined with ‘var’), but really nothing too challenging or complex.\nAnother thing that’s unique but really advantageous about GEE is the fact that projections are sorted for you, with all data being automatically converted to the Mercator projection when displayed on screen. When loading data into other platforms (I’m looking at you, QGIS), dealing with projections can be sometimes the greatest headache, so I really like that in GEE it’s all standardised ahead of any analysis you conduct.\nJust as in any other geospatial data programme, the options for analysis are never ending. You can perform a range of operations (joins, filtering etc.), and methods (machine + deep learning, classifications, etc.). Basically, there is no limit to what you can do in GEE and it performs just as well, if not better in my opinion, than other applications.\nSimply put, GEE is great and I will never fail to be shocked at how easy it makes some otherwise really arduous tasks, purely through its seamless design and focus on data analysis rather than processing."
  },
  {
    "objectID": "week5.html#applications",
    "href": "week5.html#applications",
    "title": "5  Google Earth Engine",
    "section": "5.2 Applications",
    "text": "5.2 Applications\nUpon reading the Week 5 practical content, I found myself distracted by the link to the GEE catalog - I had no idea that such a range of data was available! In particular, the MODIS Thermal Anomalies & Global Daily Fire (1km) dataset (below) stood out to me as this links quite well with the policy recommendation I made last week (see Week 4 tab).\n\n\n\nScreenshot from the GEE catalog\n\n\nThis dataset provides daily fire mask composites at a 1km resolution. The product allows users to distinguish between fire, no fire and no observation with ease and has a range of potential applications including:\n\nSpatio-temporal fire monitoring across ecosystems\nDetecting changes in fire distribution\nIdentification of new wildfires\nObservation of fire frequency/relative strength\n\nKeen to combine the taught practical skills with my policy suggestion from Week 4, I decided to test whether the product might be a suitable choice for detecting fires in Nairobi that are responsible for lowering air quality. I downloaded a shapefile of Kenya’s administrative boundaries from GADM, filtered the shapefile to obtain Nairobi’s outline (using QGIS to identify the boundary code) and uploaded this as an asset to GEE.\n\n\n\nThe Kenya boundary uploaded to my GEE assets (peep some of my past projects!)\n\n\nAfter this, I built upon the sample code provided to me in the GEE developers guide for the MODIS product, filtered my study area to Nairobi county boundaries and created a fire mask using the FireMask band.\n\nHowever, it was only at this point after running the code and trialing different dates to call for MODIS data that I realised I’d made a fundamental mistake;\n\nNo matter which dates I selected, I couldn’t seem to detect fire across my study area, despite understanding that rubbish was burnt across the city almost constantly. It was only after I returned to the product specs that I realised why this was the case. The MODIS Terra product has a resolution of 1km, which is too large to detect local fires which occur on a much smaller scale. It is unlikely that even if a pixel has several fires within it, these fires will comprise the majority of the pixel and therefore GEE is unable to mask the surface properties accordingly. This was definitely a good reminder for me that even if you’ve got experience in remote sensing, image properties continue to catch you out at times!\nWith the knowledge in mind that this product was more suited towards observation of large scale fires (typically wildfires/forestry related) than local incinerations, I sought out papers which had used the MODIS Terra data in the past to get a better sense of what it has/can be used for.\nHabibie et al.,2021 stood out to me, describing a methodology which heralds GEE’s cloud computing capabilities in the use of MODIS14A1 composites to detect fires in real time across Indonesia’s forests. They describe how efficient techniques are essential in the identification of current fires given the ability for fires to change rapidly across space and time. In their research, the authors describe how GEE is specifically suited for this job; successfully identifying fire hotspots with ‘an appreciable prediction accuracy… quick and fast’. This conclusion is evident given the working pipeline they suggest for their methodology (below), which in just 5 steps allows fires to be identified.\n\n\n\nHabibie et al.,. 2021 methodology pipeline\n\n\nI was impressed by this study on the basis of its simplicity. Often I feel as though I need to dedicate a long time to understand how a study achieved its outputs which makes me feel as though the opportunities to either replicate the study or build upon its methodology are limited. Rather, this study employed an intuitive method that could be carried out by a GEE newbie, which is good to see and feels purposeful. It’s as though they recognised that GEE can do a lot in very few lines of code and capitalised on this to demonstrate how it can be easily utilised for important real-world geospatial analysis.\nResearch by da Rocha Miranda et al.,2023 utilises a similar but more complex methodology to monitor and validate active fires using the MODIS product in GEE. Unlike Habibie et al.,this team combined several different products to model the surface of their study area (Brazil), and diagnose active fires by cross-examining data from different satellites (MODIS Sensor, MOD14A1 product active fire, and MCD64A1 product burn area images). Validation was then conducted using a range of equations (below).\n\n\n\nEquations underpinning the validation process used by da Rocha Miranda et al.,2023\n\n\nWhilst Habibie et al., 2021’s research was focused more on exploring the potential use of GEE in forest fire observation tasks, da Rocha Miranda et al., 2023 sought to integrate their methodology/findings into the current approach used by members of the Brazilian Institute of Environment and Renewable Natural Resources who are responsible for monitoring and protecting the forest. These examples feel like they demonstrate the power of GEE - it can be used by both beginners and specialists/academics alike. Moreover, it’s nice to see it being used in both purely academic as well as real-life, actionable instances. I feel convinced by these examples that GEE’s true value lies in its simultaneously simple interface and robust applications/capabilities."
  },
  {
    "objectID": "week5.html#reflections",
    "href": "week5.html#reflections",
    "title": "5  Google Earth Engine",
    "section": "5.3 Reflections",
    "text": "5.3 Reflections\nI must admit, I feel slightly silly for not having realised before writing the code in GEE that the MODIS Terra product might not be suitable for my application. That being said, my mistakes took me back to week 1’s warnings that you need to always consider the specifications of a product when using it, and that a data product’s suitability is determined not simply by its application but also according to its spatial/spectral/temporal/radiometric qualities. No matter how much confidence or experience in remote sensing you might have, these mistakes can happen easily!\nDespite this set-back, I was encouraged by the readings I described above that outline how the product has incredibly valuable real-life applications and in particular, I found it really interesting to read about how the research by da Rocha Miranda et al.,2023 informed improvements in the Brazilian Institute’s approach to monitoring deadly forest fires. The capabilities of GEE are evident, both in the amount of data that can be accessed via it and the broad range of uses it has (from simple to much more complex processing). I fully believe that GEE and cloud computing more broadly is set to change research that uses remote sensing enormously, and perhaps most excitingly, expand the opportunities for non-specialists to quickly and easily engage with data and harness it for good. Naturally, barriers to internet access remain a barrier to universe use but as this global divide reduces with time and the number of open source resources/tools to learn GEE expand, I fully believe that the web service will become utilised globally. Returning to the case of Nairobi, I definitely believe GEE could represent a highly valuable tool in facilitating the use of remote sensing data for environmental monitoring at a low cost to suit the available budgets allocated by the government to enact policy such as the Air Quality Action Plan."
  },
  {
    "objectID": "week5.html#references",
    "href": "week5.html#references",
    "title": "5  Google Earth Engine",
    "section": "5.4 References",
    "text": "5.4 References\n\nGoogle Earth Engine Data Catalog (2024) ‘MOD14A1.061: Terra Thermal Anomalies & Fire Daily Global 1km’. Web page, available at: https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD14A1\nHabibie, M.I., Nurda, N., Akbar, H.I., Bintoro, O.B., Arifandri, R., Ramadhana, N. (2021) ‘Real time monitoring fire detection using remote sensing’. IEEE Asia-Pacific Conference on Geoscience, Electronics and Remote Sensing Technology, vol. 2, pp. 28-32\nda Rocha Miranda, J., Juvanhol, R.S., da Silva, R.G. (2023) ‘Use of maximum entropy to improve validation and prediction of active fires in a Brazilian savanna region’. Ecological Modelling, vol. 475."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Classification (i)",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nThis week we were introduced to the principles and methods of classification in the context of remote sensing, focusing specifically on the role of machine learning (hereafter ML). Several ML methods were outlined including classification and regression trees (CART), random forests, maximum likelihood and support vector machine (SVM), and we also discussed image classification approaches (supervised vs unsupervised learning). Below I shall summarise the lecture content and offer a brief description of each classification method covered. Since this is newer content to me than some of what was covered in previous weeks, this summary section will be longer and more in depth as I had to spend more time learning what each method was about! Also motivating this thorough recap was the fact that I will likely come across these terms + methods in future assignments, so am hoping to have a detailed summary that I can return to when I next need a reminder of them.\n\n6.1.1 What does ‘classification’ refer to?\nIn the context of remote sensing, classification is the process of categorising all pixels in an image into classes or themes based on their spectral signatures. Often, this is used to label different land cover types/change, described by Talukdar et al.,2020 as being an ‘increasingly essential aspect of activities and applications, such as in planning for land use or global warming mitigation’. Gómez-Chova et al.,2015 consolidate this, arguing that ‘among all the products that can be obtained from the acquired images, classification maps are perhaps the most relevant ones’, as ‘land-cover and land-use maps are mandatory in multitemporal studies and constitute useful inputs to processes such as the modeling of climate change, the study of oceanic currents, arctic studies, or postcatastrophe deployments.’\n\n\n6.1.2 What are the different approaches to classifying surface types?\n\nExpert systems\n\n\nDesigned to mirror human expertise/decision making in classification of EO data\nTakes in human knowledge to emulate problem solving that usually requires human intelligence\n\n\nMachine learning (ML)\n\n\nBy contrast, ML is a set of techniques that allow computers to classify images without explicit programming\nIt uses algorithms that learn from data and improves over time (becomes more accurate) as it is exposed to more examples\nIt can then be used on new input data\n\n\n\n6.1.3 CART: Classification and regression trees\nCART is a generic term for two types of decision trees; classification and regression trees. In short however, these both represent versatile supervised ML methods.\n\nClassification trees\n\nUsed to classify data into discrete categories (ie. whether a day is cloudy or not)\n\nRegression trees\n\nUsed to predict a continuous dependent variable (ie. house prices)\n\n\nThey are decision trees where each fork is split into a predictor variable and each node has a prediction for the target variable at the end. Nodes are split into sub-nodes based on a threshold value of an attribute. The root node is taken as the training set and is split into two by considering the best attribute and threshold value. Further, the subsets are also split using the same logic. This continues till the last pure sub-set is found in the tree or the maximum number of leaves possible in that growing tree.\n\n\n\nCART diagram. Source: Freie Universität Berlin, 2019\n\n\nCART algorithms use Gini impurity to decide where to split the data. The algorithm iteratively divides the dataset into smaller subsets, choosing splits that decrease Gini impurity, aiming for homogenous nodes. This process continues until a stopping criterion is met, creating a tree where each leaf represents a predicted class or value, effectively using Gini impurity as a guide to build a model that can classify new instances. Unlike linear regression, where you seek a single coefficient used to estimate the slope of a relationship, CART provides a series of mean values for subsets of the dataset, making it suitable when dealing with non-linear datasets.\nOverfitting is a potential problem in the use of CART, which occurs when the tree model becomes too complex - meaning it closely mirrors the training data, including its noise and outliers. The effect of this is a poor generalisation on unseen data, with the model instead capturing noise rather than the underlying pattern. To mitigate against this, techniques like pruning (reducing the size of the tree by removing sections that provide little power to classify instances), setting a maximum depth for the tree, or requiring a minimum number of samples per leaf are used.\n\n\n6.1.4 Random Forest\nRandom Forest builds upon the decision trees described above - it’s an ensemble learning method that builds multiple decision trees during training and aggregates their predictions for more accurate and stable results. It randomly selects subsets of the training data and features to construct each tree, reducing the risk of overfitting. The final prediction is made by majority vote for classification tasks or averaging for regression, enhancing the predictive accuracy and robustness over single decision trees.\n\n\n\nRandom Forest diagram. Source: Yehoshua (2023)\n\n\nBootstrapping and out-of-bag (OOB) error are two additional features of Random Forest algorithms that need explaining. Bootstrapping is a technique where multiple datasets are created from the original by randomly sampling with replacement, used to train individual trees. Out-of-bag (OOB) error is an accuracy estimate calculated from predictions on the training instances not included in the bootstrap sample for a tree. It serves as an internal validation method, offering insights into the model’s performance without needing a separate test set.\nWhilst Random Forest handles overfitting better than singular decision trees and improves its accuracy through ensemble learning, it is more complex - a problem which can lead to slower model training and prediction times and pose challenges in interpreting the model compared to a single decision tree. However, decision trees may struggle to achieve the level of accuracy as random forests on complex datasets.\n\n\n6.1.5 Image classification\nWe also discussed image classification; the process whereby images are categorised into one or more classes based on their content. There are two method types for this, supervised and unsupervised.\n\nSupervised\n\n\nUses labelled training data to classify pixels into categories\nAlgorithm learns from training data, where examples are labelled correctly\nThis is used to recognise patterns/features corresponding to each category\nOverall process: selecting training samples -&gt; training the classifier -&gt; applying it to classify whole dataset\nParametric\nEG. Maximum likelihood, Support Vector Machine (SVM)\n\n\nUnsupervised\n\n\nDoesn’t require labelled training data\nAlgorithms automatically segment input data into clusters based on inherent patterns/data similarities\nNo a priori knowledge needed\nUseful for when there are unknown data patterns or when specific class labels aren’t provided/available\nNon-parametric\nEG. Clustering (K-means), ISODATA\n\n\n\n6.1.6 Maximum likelihood\nThis is a decision rule classifier that assigns pixels/groups of pixels to the class with the highest probability of being correct based on a pixel’s spectral signature. To work it uses the mean and covariance of the classes in a multidimensional feature space to estimate probabilities.\n\n\n\nMaximum likelihood diagram. Source: Wicklin, 2011\n\n\nThis makes it a highly effective approach when distinguishing between classes with different statistical characteristics. It can also use a threshold for hyperparameter tuning through the input of a priori knowledge, however it must be noted that this isn’t always available.\n\n\n6.1.7 Support Vector Machine (SVM)\nWhilst similarly being a data classifying algorithm, SVMs work by finding the optimal hyperplane that separates different class labels in a high-dimensional space. Ultimately, it is a linear binary classifier (like logistic regression), but is effective on both linear and non-linear data, working by using kernel functions to transform nonlinear input space into a higher-dimensional space where it becomes easier to classify the data. It focuses on maximizing the margin between different classes, which enhances the model’s accuracy and robustness in classification tasks. To understand this method I found this video extremely helpful but ultimately, it clearly explains how the algorithm seeks to find a singular hyperplane that best separates the data into categories.\n\n\n\nHyperplane separating the dataset into categories. Source: Visually Explained (YouTube), 2022\n\n\nTherefore, whilst SVMs and maximum likelihood are both approaches to classify data, they differ in some key ways. Whilst SVM is more robust and better suited for handling complex, non-linear data, maximum likelihood is preferential at times on the basis of its probabilistic foundation which makes it effective in remote sensing application.\n\n\n6.1.8 Additional important considerations\nFinally, we were reminded (much like in week 1) that no single algorithm was better than another. Instead, there are key considerations which must be taken when thinking about which approach to use, including:\n\nWhether you want to classify pixels or objects\nWhether you want to run a hard or soft classification\nWhether classifiers are even needed (is there a clear divide between bands? Can data just be thresholded?)\nWhich hyperparameters do we want to use to control the classifier?\nAre you more worried about accuracy or interpretability?\n\n\n\n\nThe trade off between achieveable accuracy and interpretability of ML algorithms. Source: Pichler et al. 2022\n\n\nAt the end of the day, classification methods are different ways of slicing data - they can be made to seem more complicated than they really are!!"
  },
  {
    "objectID": "week6.html#applications",
    "href": "week6.html#applications",
    "title": "6  Classification (i)",
    "section": "6.2 Applications",
    "text": "6.2 Applications\nWhat stood out to me from this week’s lecture content was the fact that there are so many considerations that go into picking a classifier. In particular, I really liked the diagram (above) that graphically presented the trade off between accuracy and interpretability of different algorithms as it really demonstrated how high accuracy didn’t necessarily represent the best choice, despite what I assumed going into this week. As a result, when I was doing reading for this week I found myself drawn to papers which reviewed and compared classifiers against one another - I shall outline some of my findings in this section.\nThe first that piqued my interest was that by Yao et al., 2022, who compared classifiers mentioned in the lecture content (random forest) against additional classifiers not discussed (object-oriented and deep neural networks) to see which were most accurate when classifying crops in Qinghai Province, China. They found that using a combination of random forest and deep neural networks, the method returned a model accuracy, training and predict time spent were better than that of using either classifier alone. I found it really interesting the way that they not only used GEE, but also Google Colab in their methodology, presented in this diagram below.\n\n\n\nRandom forest + deep neural network classification method flowchart. Source: Yao et al. 2022\n\n\nThey actually note the strength of these platforms in the paper, describing how the ‘scalable and simple classification method proposed in this paper gives full play to the advantages of cloud platform in data and operation, and the traditional machine learning combined with deep learning can effectively improve the classification accuracy’. This line stood out to me as it really built upon the conclusions I drew from last week’s content about cloud computing representing an enormous development in the world of remote sensing research.\nBy contrast to the findings of Yao et al., 2022, Kamal et al.,’s 2019 research found SVM to be the most suitable classifier out of random forest and CART approaches tested on efforts to map mangrove extents in Indonesia using GEE.\n\n\n\nClassifier accuracy assessment results. Source: Kamal et al., 2019\n\n\nWhilst they noted the ability of all classifiers to detect mangrove objects (a key finding given the relevance + importance of mangrove monitoring for ecosystem stabilisation), SVM’s classification results were described as being significantly better than the other classification methods and the method showed the least amount of miss-classified pixels. This demonstrates exactly the point made during the lecture; there is no one-classifier-fits-all! Also consolidating the practical content was Kamal et al.,‘s heralding of GEE, describing how it provides ’a set of the state-of-the-art classifiers for pixel-based classification’.\nOther papers that I read but shan’t describe here include Hird et al.’s 2017 use of classifiers in GEE to support wetland mapping in Canada, Praticò et al.’s (2021) classification application for forest habitat monitoring in Italy and Sarzynski et al.’s 2020 mapping of oil palm plantations in Indonesia which used GEE’s quality classifiers. These papers all demonstrate the varied contexts in which classification methods have been used in robust GEE-based research to monitor landscape type/use/change!"
  },
  {
    "objectID": "week6.html#reflections",
    "href": "week6.html#reflections",
    "title": "6  Classification (i)",
    "section": "6.3 Reflections",
    "text": "6.3 Reflections\nGoing into this week, I really didn’t know very much about the different classification approaches available so had to spend quite a long time familiarising myself with them. I found watching YouTube explanations to be my best friend for the job and this meant that the summary section of this week’s blog post is longer than any of my previous ones - apologies for this!\nI really enjoyed reading about the enormous variety of applications for each classifier and although I only mentioned environmentally-focused research papers, I also found a breadth of urban-based papers that had similarly trialed several classifiers and assessed their accuracy before proceeding with further analysis. I’m glad I did that literature review as it really consolidated the point made during the lecture about the range of applications for classifiers in remote sensing contexts. I avoided clicking on non EO-data related papers but did scroll past several that were medically related (notably, I saw lots of tumour research come up), which is always something I find interesting and reminds me that so many of the principles we learn about are transferable to entirely different industries/research topics.\nAll of this being said, I feel as though most of my time this week was spent trying to really understand the content which left me less time than I would’ve liked for reading published work. I’m not sure if this was perhaps caused by the double lecture/no practical set up of the week, but part of me feels as though this content could’ve done with being stretched out over two lecture sessions, instead of being covered more briefly in one. I appreciate that because of this, my entry for this week is less evenly balanced as I usually like - sorry for this! I look forward to next week when I can hopefully prioritise my literature review more and really dig into the applications."
  },
  {
    "objectID": "week6.html#references",
    "href": "week6.html#references",
    "title": "6  Classification (i)",
    "section": "6.4 References",
    "text": "6.4 References\n\nFreie Universität Berlin (2019) ‘Classification and Regression Trees (CART) - Classifier’. Web page, available at: https://www.geo.fu-berlin.de/en/v/geo-it/gee/3-classification/3-1-methodical-background/3-1-1-cart/index.html\nGómez-Chova, L., Tuia, D., Moser, G., Camps-Valls, G. (2015) ‘Multimodal Classification of Remote Sensing Images: A Review and Future Directions’. Proceedings of the IEEE, vol. 103, is. 9.\nHird, J.N., DeLancey, E.R., McDermid, G.J., Kariyeva, J. (2017) ‘Google Earth Engine, Open-Access Satellite Data, and Machine Learning in Support of Large-Area Probabilistic Wetland Mapping’. Remote Sensing, vol. 9, is. 12.\nKamal, M., Jamaluddin, I., Parela, A., Farda, N.M. (2019) ‘Comparison of Google Earth Engine (GEE)-based machine learning classifiers for mangrove mapping’. 40th Asian Conference on Remote Sensing, ACRS.\nPichler, M., Hartig, F. (2022) ‘Machine Learning and Deep Learning -- A review for Ecologists’. Biomedical Signal Processing, vol. 1.\nPraticò, S., Solano, F., Di Fazio, S., Modica, G. (2021) ‘Machine Learning Classification of Mediterranean Forest Habitats in Google Earth Engine Based on Seasonal Sentinel-2 Time-Series and Input Image Composition Optimisation’. Remote Sensing, vol. 13, is. 4.\nSarzynski, T., Giam, X., Carrasco, L., Lee, J.S.H. (2020) ‘Combining Radar and Optical Imagery to Map Oil Palm Plantations in Sumatra, Indonesia, Using the Google Earth Engine’. Remote Sensing, vol. 12, is. 7.\nTalukdar, S., Singha, P., Mahato, S., Pal, S., Liou, Y-A., Rahman, A. (2020) ‘Land-Use Land-Cover Classification by Machine Learning Classifiers for Satellite Observations—A Review’. Remote Sensing, vol. 12, is. 7.\nVisually Explained (2022) ‘Support Vector Machine (SVM) in 2 minutes’. YouTube video, available at: https://www.youtube.com/watch?v=_YPScrckx28\nWilkin, R. (2011) ‘Maximum likelihood estimation in SAS/IML’. Web page, available at: https://blogs.sas.com/content/iml/2011/10/12/maximum-likelihood-estimation-in-sasiml.html\nYao, J., Wu, J., Xiao, C., Zhang, Z., Li, J. (2022) ‘The Classification Method Study of Crops Remote Sensing with Deep Learning, Machine Learning, and Google Earth Engine’. Remote Sensing, vol. 14, is. 12.\nYehoshua, R. (2023) ‘Random Forests’. Web page, available at: https://medium.com/@roiyeho/random-forests-98892261dc49"
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  Classification (ii)",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nThis week we were discussing how to classify data and considered object based image analysis (OBIA) and sub-pixel analysis, before moving on to discuss measures of accuracy. I will summarise these below - I promise it will be more brief than last week!\n\n7.1.1 Object based image analysis (OBIA)\n\n\n\nScreenshot of object based image analysis in action. Source: GIS Geography\n\n\nEssentially, this is when you analyse EO data by dividing the image into meaningful objects/segments rather than by processing individual pixels. This is conducted by considering shapes based on the similarity or difference between cells. Simple Linear Iterative Clustering (SLIC) is the most common method and works by laying a regular grid of points across an image and using this to calculate the distance from the point to the neighbouring pixel, making objects as it classifies across the image.\n\n\n7.1.2 Sub-pixel analysis\nIn instances where a singular pixel may be composed of various different land cover types, sub-pixel analysis can be used to support classification efforts. This technique is used to estimate the fraction of each pixel that is covered by different materials/land cover types. I really liked mention of the VIS model during this part of the lecture as I’d never heard about it before - it’s a conceptual framework used to describe the land types in urban environments that is underpinned by a premise that urban areas can be characterised by three main components: vegetation, impervious surfaces (eg. concrete) and soil.\n\n\n\nVIS model. Source: Plaza et al.,2002\n\n\n\n\n7.1.3 Accuracy\nAfter discussing these, we were taught about how accuracy is measured in remote sensing and machine learning. At the end of the day, the things that are monitored are:\n\nProducer accuracy: classification results meet creator expectations\nUser’s accuracy: pixels incorrectly classified as a known class when they should’ve been classified as something else\nOverall accuracy\n\nAs if remembering all of those isn’t enough to juggle, you also need to consider true positive/negative and false positive/negative when assessing a model’s performance.\nAt this point, I was reassured to hear some discussion of things I have already become familiar with, like the benefits of cross validating classification models by splitting the dataset into training/testing sets. What was new to me however was the explanation of spatial cross-validation. This is a method used to evaluate the performance of spatial models, taking into account the spatial autocorrelation inherent in geographic data (hello, Tobler!). Unlike normal cross-validation, spatial cross-validation partitions the data into training and testing sets in a way that respects the spatial autocorrelation. This involves grouping together spatially close observations, ensuring that the training/testing sets are spatially separated. Ultimately, this ensures a more realistic assessment of the model’s performance when predicting outcomes for new and unseen locations."
  },
  {
    "objectID": "week7.html#applications",
    "href": "week7.html#applications",
    "title": "7  Classification (ii)",
    "section": "7.2 Applications",
    "text": "7.2 Applications\nMentioned during the lecture for its arguably harsh title, I read Karasiak et al.,‘s 2021 paper ’Spatial dependence between training and test sets: another pitfall of classification accuracy assessment in remote sensing’. I found this paper really interesting and a perfect compliment to the week’s discussion of spatial autocorrelation’s effect on accuracy. The authors argue that all too often, spatial autocorrelation is not accounted for in image classification, leading to bias in accuracy metrics. They demonstrate this through experiments on Sentinel-2 data for forest classification that find the spatial leave-one-out cross-validation is the most accurate and least biased in it results.\nI found their argument very compelling - I hadn’t considered the potential effects of spatial autocorrelation on classification tasks, despite having run some ML models in the past at work. Clearly I am not alone in that however, and was amused to read the following section which demonstrated exactly that.\n\n\n\nPerhaps I was wrong for rolling my eyes at the constant reminders to keep Tobler’s first law in mind at all times!\n\n\nFrom this I was inspired to return to papers I had come across before to see whether or not spatial autocorrelation was accounted for in classification models that perhaps would’ve benefitted from them. One that I was reminded of was Muchoney et al., 2002’s STEP model which impressively described site vegetation, environment and other biophysical parameters through its classification system. Whilst the paper is impressive in terms of the scope of mapping it permits as well as the ways in which it builds upon past similar studies, I realise now upon rereading it that it doesn’t acknowledge any potential effect of spatial dependence. Whether or not they did consider this I don’t know - what I do know however is that without mention of it in the methodology, I wonder what a difference it would’ve made on the model’s accuracy had they accounted for it. This is particularly relevant for this study as they seek to create a map of Central America which to me, sounds like it will indeed be affected by spatial autocorrelation.\nI assumed that perhaps more recent papers seeking to employ similar methodologies might differ and instead more obviously mention this potential study pitfall. However after reading through Ganem et al.,’s 2022 review of papers employing classification models to map South America’s drylands, this does not appear to be the case. Broadly, discourse appears to be dominated by discussion of comparing models and specifically, comparing their overall accuracy (%). Whilst this is important, I was surprised to see that no attention was paid to spatial cross-validation, and equally as surprised to see that reasons behind highly accurate models were not being attended to. Although getting a highly accurate score is undoubtedly important, I think that more studies should look backwards on a high score and consider what the reasons for it might be so as to ensure models are not benefiting from the effects of processes like spatial autocorrelation impacting testing/training sets and potentially increasing the accuracy of models."
  },
  {
    "objectID": "week7.html#reflections",
    "href": "week7.html#reflections",
    "title": "7  Classification (ii)",
    "section": "7.3 Reflections",
    "text": "7.3 Reflections\nIf I’m being honest, I found this week’s content harder to work my way through than the weeks prior. Realistically, I think I probably saw the slides on accuracy and was slightly overwhelmed by the variety of different ways to measure accuracy, only to be thrown off further by the discussion of matrices which conceptually never come quickly to me. That being said, I was excited by the spatial autocorrelation mention as this was something I really enjoyed learning about in CASA005 and in my Principles of Spatial Analysis course with Anwar Musah. I definitely know that next time I’m doing modelling with remote sensing I’ll bare it in mind, as I was dwelling on past projects I had done during my internships and realised never before had its potential effects been mentioned! I will also in future be thinking much more about my model accuracy scores and make sure that I trial different ways of boosting my study accuracy.\nBeyond what I’m taking on from this week personally, I also considered the future for literature given these reflections. It would be good to see much more consideration of accuracy in published work and specifically a discussion of different measures of accuracy for models run. Perhaps what I’m after is some kind of review paper that brings different papers covering a similar area of research (EG. South American land use classification tasks) together and compares the ways in which authors discuss the accuracy of their work. I would assume at the very least, a paper like that would prompt future researchers to consider this more and get the ball rolling on improving it more broadly. Karasiak et al., 2021 are a step in the right direction, but more of this, please!!"
  },
  {
    "objectID": "week7.html#references",
    "href": "week7.html#references",
    "title": "7  Classification (ii)",
    "section": "7.4 References",
    "text": "7.4 References\n\nGanem, K.A., Xue, Y., Rodrigues, A.A., Franca-Rocha, W., Oliviera, M.T., Carvalho, N.S., Cayo, E., Rosa, M., Dutra, A., Shimabukuro, Y.E. (2022) ‘Mapping South America’s drylands through remote sensing - A review of the methodological trends and current challenges’. Remote Sensing, vol. 14, is. 3.\nGIS Geography (2023) ‘OBIA - Object-Based Image Analysis (GEOBIA)’. Web page, available at: https://gisgeography.com/obia-object-based-image-analysis-geobia/\nKarasiak, N., Dejoux, J.F., Monteil, C., Sheeren, D. (2021) ‘Spatial dependence between training and test sets: another pitfall of classification accuracy assessment in remote sensing’. Machine Learning, vol. 111, pp. 2715-2740.\nMuchoney, D., Borak, J., Chi, H., Friedl, M., Gopal, S., Hodges, J., Morrow, N., Strahler, A. (2000) ‘Application of the MODIS global supervised classification model to vegetation and land cover mapping of Central America’. Int. Journal of Remote Sensing, vol. 21, no. 6 & 7, pp. 1115-1138\nPlaza, A., Martinez, P., Perez, R., Plaza, J. (2002) ‘Spatial/spectral endmember extraction by multidimensional morphological operations’. IEEE Transactions on Geoscience and Remote Sensing, vol. 40, no. 9, pp. 2025-2041"
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "8  SAR",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nThis week we pivoted from passive optical images to another type of remote sensing; synthetic aperture radar aka SAR! SAR sensors produce their own energy and then record the amount of that energy reflected back after interacting with the Earth, requiring a unique way of interpreting the data as the signal obtained is responsible to surface characteristics like topography and moisture. To summarise this week’s content I returned to a handwritten approach (as used in weeks 1 and 3) which is pictured below.\n\n\n\nWeek 8 SAR summary\n\n\nThe key things to remember from this week’s content serve as the subheadings in the above mind map. I was particularly excited to finally experience that penny-drop feeling when realising that several papers I had read over the past few weeks had utilised SAR data, celebrating its strengths over optical data for certain applications (specifically for night-time monitoring + observations over frequently cloudy study sites). That was probably what I found most interesting from this week’s content - understanding the humongous potential for observation when using a combination of both passive and active sensor data in research! That, and of course discussion of interferometry. Having worked on a 2-man interferometry team at a job I had in London last summer, I think I’ll be forever amazed by not only the power it holds for obtaining incredibly precise ground measurements, but also by the crazy rainbow appearance of an inteferogram.\n\n\n\nExample of an unwrapped interferogram generated by SNAP user vin15carter. Source: STEP Forum, 2017"
  },
  {
    "objectID": "week8.html#applications",
    "href": "week8.html#applications",
    "title": "8  SAR",
    "section": "8.2 Applications",
    "text": "8.2 Applications\nCombining my interest in InSAR with the fascinating discussion of Ollie Ballinger’s work on detecting building damage in conflict affected areas, I have decided to dedicate this applications section to exploring this line of research more thoroughly. As my dissertation is focusing on predicting terrorism + associated conflict risk, I was really excited to delve into the topic more!\nThe first paper that I came across outlined the work that Boloorani et al.,2021 had done using InSAR to map post-war urban damage in Mosul, Iraq. They sought to assess the feasibility of implementing InSAR techniques on Sentinel-1 data to estimate post-war damage as an alternative to using commerical high-res optical imagery. What I thought was really curious about this paper was that they assessed their outputs to a UN (UNITAR) damage map that had been commissioned by the Iraqi government after the Battle of Mosul in 2016-2017 - a map that had been generated using a combination of data sources including drone imagery, satellite images and field visits to create a post-war damage map.\n\n\n\nMosul damage severity map. Source: UNITAR-UNOSAT, 2019\n\n\nWhat this meant was that the discussion of the study’s successes/accuracy hinged almost entirely on comparison between study outputs and the above UN map. Before I launch into a critique of this, I do want to confess that I really liked the way in which they tested + graphically presented the comparison between the two - it seems really intuitive to me which is a nice break from the sometimes unintelligible analysis that I see in similar papers using InSAR techniques.\n\n\n\nCross comparison of the UNITAR results with the study’s displacement map (called SBAS). The authors overlayed the UN’s damage severity points over the study’s gridded damage map to demonstrate how, at the local level, the two differed. Source: Boloorani et al., 2021\n\n\nReading the discussion section of this paper, I couldn’t shake what Ollie said out of my mind. He spoke about how often, in the case of machine learning + remote sensing research, the results of accuracy assessments were disorted as overfitting was prevalent, thereby preventing opportunities to re-use a method in a new study location. It feels as though a similar issue affects this research. What would happen if they ran the same processes on say, Yemen, if there were no maps to support cross comparison? It seems to me at least, that there would be no proper way to assess the accuracy of outputs. Not only that, but the way that the discussion section is written suggests that strong prior ground knowledge of the war is important in interpretation efforts. This left me feeling ever so slightly frustrated, as I feel like I got lured in with a snappy title, a slick abstract and a series of interesting looking maps. It’s only at the end of the paper that the authors admit that whilst InSAR can capture damage, it’s probably only really useful when integrated with other data sources like the UN map. Even more than that, they also describe failings of the technique to detect a sudden decrease in building height and a strong reliance on ground data - a luxury often impossible in conflict-affected areas. Undoutbedly, the final line of the paper rings true: ‘This could be an issue to be followed in future research’.\nIn some of the ways in which Boloorani et al.,2021 went wrong, I believe Aimaiti et al. 2022 built upon and improved. They sought to assess building damage caused by war in Ukraine using Sentinel-1 SAR data and Sentinel-2 optical images, comparing their results to a UN Satellite Centre (UNOSAT) damage assessment map. Right off the bat, the authors acknowledge the problems acquiring ground truth data in the ongoing war zone, describing how for this reason their accuracy assessments are twofold, both qualitative and quantitative. These assessments are integrated into the study’s methodology and are frequently referred back to throughout the text, demonstrating the authors awareness of the study’s inherent limitations.\n\n\n\nBuilding damage mapping workflow. I particularly like the way that the validation of results is presented here. Source: Aimaiti et al. 2022\n\n\nAlso unlike Boloorani et al.,2021’s paper, Aimaiti et al. 2022 provide much more specific + detailed information about the steps they took throughout their methodology which is nice to see as all too often I feel like I read papers that I have 0 chance of recreating myself due to the lack of processing information.\nIn terms of results, Aimaiti et al. 2022 obtained some slightly confusing outputs - there were a few locations where damage detected by Sentinel-1 contradicted results from Sentinel-2. Broadly however, they found that the contribution to damage classification by either data type depended on the scale at which change was assessed; S1 showed small to large scale damaged buildings, while optical texture-based analysis mainly showed the large-scale damaged buildings. Similar to Boloorani et al.,2021, they presented their findings relative to the UN map in a simple graphical format.\n\n\n\nThe comparison of the Sentinel-1 SAR intensity-based results with the UNOSAT’s building damage assessment report. Source: Aimaiti et al. 2022\n\n\nOverall, I preferred this paper for several reasons. Besides those already mentioned, I feel as though this was written in a more self-aware way; by that, I mean that rather than selling the dream of a valuable methodology for detecting building damage in conflict afflicted areas and then admitting to falling short within the final few lines of the discussion section, Aimaiti et al. 2022 are more critical and display a greater consciousness of the challenges inherent to this task throughout. Moreover, I really like the way that they integrate both active and passive remotely sensed data into their analysis, as this makes results more robust. Finally, I like the direction in which they suggest future research to be aimed, describing a keen interest to ‘extend the framework to detect other war related damages, such as damages to agricultural sectors, and road/infrastructure non-building damages’.\nAll in all, I think that both of these papers clearly demonstrate both the case that Ollie was making in the lecture and the discussion of accuracy assessments from the week prior - in all contexts, there are challenges to assessing the accuracy and success of a technique in making detailed observations from space. But moreso than any other context, when conflict is affecting an area this becomes even more challenging. This remains a fertile and incredibly pressing area of research which will only benefit from more work being conducted.\nUnrelated to all of this but something cool that I saw when doing some reading was about the use of interferometry in art restoration. Turns out it’s a technique that is used quite widely by restoration specialists in detecting where otherwise invisible defects are in paintings. It is increasingly becoming a vital structural diagnosis tool and supports conservation efforts.\n\n\n\nPainting of Saint Sebastian (left), its holographic interferogram (right). The technique was used here to identify the location of structural defects in the painting’s wooden panelling. Source: Tornari, 2008\n\n\nFrom art to conflict studies, interferometry has us all covered!"
  },
  {
    "objectID": "week8.html#reflections",
    "href": "week8.html#reflections",
    "title": "8  SAR",
    "section": "8.3 Reflections",
    "text": "8.3 Reflections\nI really really loved this week’s content - in fact, I’d actually say that of all the weeks, this has been my favourite. It really felt like a lot of the things we had been discussing came together in one, especially when using conflict and war as the lens to consider the content through. Currently, I’m planning on creating a spatial risk map of terrorism in Nigeria for my dissertation using a Bayesian framework. However after this week, I’m strongly considering pivoting my research to include remotely sensed data to see whether or not this could be a valuable input in my risk analysis. I truly believe this is an incredibly important area of research and I look forward to seeing Ollie’s paper get published as his lecture really stuck with me.\nI also wanted to briefly mention how much I’ve enjoyed this assessment style. To avoid sounding like I’m begging for a better mark through praise, it has been really nice to have the opportunity to really engage with published literature and see how the concepts that we get taught in a theoretical way can be used actively in really interesting/diverse fields. I really feel as though I’ve come a long way from week 1 in terms of the way I engage with and critique the literature that I come across. In the past I’d always felt hesitant to say anything that wasn’t complimentary about published work, as it felt a bit rich given that it wasn’t like I knew how to do what the authors did. Having now fully learnt about sensors, methods and even having trialed them myself during the practicals, I feel much more confident overall about my understanding and my opinions. It’s cool - I think this is actually something that will stay with me from here on out. Cheers CASA.\nSo that concludes my learning diary! I hope you’ve enjoyed it - I definitely have!"
  },
  {
    "objectID": "week8.html#references",
    "href": "week8.html#references",
    "title": "8  SAR",
    "section": "8.4 References",
    "text": "8.4 References\n\nAimaiti, Y., Sanon, C., Koch, M., Baise, L.G., Moaveni, B. (2022) ‘War related building damage assessment in Kyiv, Ukraine, using Sentinel-1 radar and Sentinel-2 optical images’. Remote Sensing, vol. 14, is. 24.\nBoloorani, A.D., Darvishi, M., Weng, Q., Liu, X. (2021) ‘Post-war Urban Damage Mapping Using InSAR: The Case of Mosul City in Iraq’. ISPRS Int. J. Geo-Inf., vol. 10, is. 3.\nTornari, V. (2008) ‘Handbook on the use of lasers in conservation and conservation science’. COST Office: Warsaw.\nvin15carter via STEP Forum (2017) ‘Interferogram and displacement comparison between SNAP and DIAPASON in GEP’. Web page, available at: https://forum.step.esa.int/t/interferogram-and-displacement-comparison-between-snap-and-diapason-in-gep/5750"
  }
]